{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#! switch_R 3.3\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sabinasloman/Box/LoP/pyspan/pyspan/config.py:19: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 499, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/tornado/ioloop.py\", line 1073, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 456, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 486, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2724, in run_cell\n",
      "    self.events.trigger('post_run_cell')\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/IPython/core/events.py\", line 74, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.py\", line 164, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/IPython/core/pylabtools.py\", line 315, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/matplotlib/__init__.py\", line 1425, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/matplotlib/backends/__init__.py\", line 17, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  mpl.use(settings[\"mpl_backend\"])\n",
      "/Users/sabinasloman/Box/LoP/pyspan/pyspan/ratings_task/data.py:27: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  all_ = pd.concat((partisan, antonyms))\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pygam\n",
    "from pyspan.config import *\n",
    "from pyspan.ratings_task.analysis import freq_df, n_utterances, SparseLR\n",
    "from pyspan.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = pickle.load(open(paths[\"metrics_dir\"] + \"signals-unigrams\"))\n",
    "words = pd.read_csv(\"{}synonyms.csv\".format(paths[\"synonyms_task_path\"]))\n",
    "words = words.loc[range(7) + range(8,26)][[\"D\",\"R\"]]\n",
    "words = np.ravel(words)\n",
    "signals = dict(zip(words, \n",
    "                   map(lambda w: signals.loc[w][\"rmetric\"], words)))\n",
    "valence_data = pd.read_csv(\"valence_data.csv\")\n",
    "valences = dict(zip(np.ravel(valence_data[[\"D\",\"R\"]]), \n",
    "                    np.ravel(valence_data[[\"D_valence\",\"R_valence\"]]))\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"responses.csv\")\n",
    "df.rename(columns = { \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5 },\n",
    "          inplace = True)\n",
    "df.replace({ \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5 }, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_party_cols = map(lambda i: \"list{}_party\".format(i), range(1,6))\n",
    "list_cols = map(lambda i: \"list{}\".format(i), range(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.811764705882354 0.8264673367019187\n",
      "102 66\n",
      "0.788235294117647\n"
     ]
    }
   ],
   "source": [
    "# Some demographics\n",
    "print np.mean(df.age[~np.isnan(df.age)]), stats.sem(df.age[~np.isnan(df.age)])\n",
    "print len(df.loc[df.gender == 2]), len(df.loc[df.gender == 1])\n",
    "voted = df.voted.values\n",
    "voted[voted == 2] = 0\n",
    "print np.mean(voted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmask = np.ma.masked_where(df[list_party_cols] == \"democrat\", \n",
    "                           df[range(1,6)])\n",
    "ddat = dmask.data[dmask.mask]\n",
    "rmask = np.ma.masked_where(df[list_party_cols] == \"republican\", \n",
    "                           df[range(1,6)])\n",
    "rdat = rmask.data[rmask.mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.9569377990430623, 0.0693050521522237)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rdat[~np.isnan(rdat)]), stats.sem(rdat[~np.isnan(rdat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.5416666666666665, 0.0668167458693751)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ddat[~np.isnan(ddat)]), stats.sem(ddat[~np.isnan(ddat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4152711323763958"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rdat[~np.isnan(rdat)]) - np.mean(ddat[~np.isnan(ddat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddat_ = dmask.data.copy().astype(\"float\")\n",
    "ddat_[~dmask.mask] = np.nan\n",
    "rdat_ = rmask.data.copy().astype(\"float\")\n",
    "rdat_[~rmask.mask] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Loading required package: lme4\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Loading required package: Matrix\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: \n",
      "Attaching package: ‘lmerTest’\n",
      "\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: The following object is masked from ‘package:lme4’:\n",
      "\n",
      "    lmer\n",
      "\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: The following object is masked from ‘package:stats’:\n",
      "\n",
      "    step\n",
      "\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Type III Analysis of Variance Table with Satterthwaite's method\n",
       "       Sum Sq Mean Sq NumDF DenDF F value    Pr(>F)    \n",
       "groups 36.636  36.636     1   848   18.62 1.783e-05 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i ddat_,rdat_\n",
    "# https://www.r-bloggers.com/how-to-do-repeated-measures-anovas-in-r/\n",
    "y <- c(t(ddat_), t(rdat_))\n",
    "n <- dim(ddat_)[1]\n",
    "stopifnot(n == dim(rdat_)[1])\n",
    "kd <- dim(ddat_)[2]\n",
    "kr <- dim(rdat_)[2]\n",
    "clusters <- c(rep(1:n, each = kd), rep(1:n, each = kr))\n",
    "groups <- c(rep(0, n*kd), rep(1, n*kr))\n",
    "fit <- aov(y ~ groups + Error(clusters/groups))\n",
    "summary(fit)\n",
    "\n",
    "library(lmerTest)\n",
    "fit <- lmer(y ~ groups + (1|clusters))\n",
    "anova(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute an individual-level effect size and test the hypothesis that it's greater than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def participant_diff(i):\n",
    "    djudgments = dmask.data[i,dmask.mask[i,:]]\n",
    "    djudgments = djudgments[~np.isnan(djudgments)]\n",
    "    rjudgments = rmask.data[i,rmask.mask[i,:]]\n",
    "    rjudgments = rjudgments[~np.isnan(rjudgments)]\n",
    "    return cohensd(rjudgments, djudgments)\n",
    "    \n",
    "participant_diff = np.vectorize(participant_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sabinasloman/Box/LoP/pyspan/pyspan/utils.py:221: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return diff / spooled\n"
     ]
    }
   ],
   "source": [
    "pdiffs = participant_diff(np.arange(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43631199740173376, 0.09383669882152874)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi41LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvSM8oowAAFc9JREFUeJzt3X2wXXV97/H3V0RCCIRccnhKcjjEYlouo4gZBKMUDe1NS5S2Q2fCJbZpuZ4ZWrjK0MlA9CLVlksVn0ZuaWOloYUhOhF6W8CWB2XiA6IJBgkkSickEggmIE8pgjx87x9rh3t6svc52Q9n77XXeb9m9uyz1nedvb77kHz45bfW/p3ITCRJ/e8NvW5AktQZBrokVYSBLkkVYaBLUkUY6JJUEQa6JFWEga6+EhEPRsTpve5DKiMDXaUSEVsj4oxR+5ZFxLcBMvO/Zubd47zGUERkRLxxAluVSsdAl5rk/yhUVga6+srIEXxEnBwR6yLiuYj4WUR8tnbY2trzMxGxOyJOjYg3RMTHImJbROyMiH+IiOkjXvcParWnIuJ/jTrP5RGxJiKuj4jngGW1c98TEc9ExI6IuDoi3jTi9TIi/iQiHo6I5yPikxHx5oj4bq3fr448XuoEA1397AvAFzLzEODNwFdr+0+rPR+amdMy8x5gWe3xXmAuMA24GiAijgf+GjgXOAqYDswada6zgDXAocANwKvARcBM4FRgIfAno77nvwHvAE4BlgMrgaXAHOAE4Jw23ru0FwNdZfRPtZHvMxHxDEXY1vMy8CsRMTMzd2fm98Z4zXOBz2bmlszcDVwKLKlNn5wN/EtmfjszfwlcBoxe5OiezPynzHwtM3+Rmesz83uZ+UpmbgX+Fvj1Ud/zqcx8LjMfBDYCt9fO/yzwdeDt+/4jkcZnoKuMficzD93zYO+R7x7nAW8BNkfEDyJi8RiveTSwbcT2NuCNwBG12qN7Cpn5AvDUqO9/dORGRLwlIm6JiCdq0zBXUIzWR/rZiK9/UWd72hj9Sk0z0NW3MvPhzDwHOBz4K2BNRBzE3qNrgMeBY0ZsDwKvUITsDmD2nkJEHAgcNvp0o7avATYDx9WmfFYA0fq7kdpnoKtvRcTSiBjIzNeAZ2q7XwN21Z7njjj8RuCiiDg2IqZRjKi/kpmvUMyNvz8i3lW7UHk544fzwcBzwO6I+FXg/E69L6lVBrr62SLgwYjYTXGBdEltfvsF4C+B79Tm4U8BrgX+keIOmEeAF4ELAWpz3BcCqylG67uBncBLY5z7z4D/DjwPfAn4SuffntSc8BdcSP9ZbQT/DMV0yiO97kfaV47QJSAi3h8RU2tz8FcBDwBbe9uV1BwDXSqcRXHh9HHgOIrpG//5qr7ilIskVYQjdEmqiK4uMjRz5swcGhrq5inVT577cfF8yLzi+cmHi+eZx+1dkyaR9evXP5mZA+Md19VAHxoaYt26dd08pfrJnacXz2fcXTz//ZnF8x/dundNmkQiYtv4RznlIkmV4brOKo8TPtZaTRJgoKtMjjyjtZokwCkXlcnTG4pHszVJgCN0lcn6jxTP9S58jlWTBDhCl6TKMNAlqSIMdEmqCANdkirCi6LqiaFLbt1r30lTF3PT+e+q/w1vu2KCO5L6n4Gu0rjvhV+DgQaB3mi/pNc55aLSOGnqJtj13frFXd9tXJMEGOgqkeVHXgf3r6hfvH9F45okwECXpMow0CWpIgx0SaoIA12SKsLbFlUan3h8mNt+/z31i+/4fHebkfqQga7SeOjFuTDjxPrFRvslvW7cKZeIuDYidkbExjq1iyMiI2LmxLSnyWTBtA3wxJ31i0/c2bgmCdi3OfRVwKLROyNiDvCbwE873JMmqQsPXw0b/6J+ceNfNK5JAvYh0DNzLfDzOqXPAcuB7HRTkqTmtXSXS0ScBTyWmfd3uB9JUouavigaEVOBFRTTLfty/DAwDDA4ONjs6dQB9VY2BNh65Zld7kTSRGplhP5m4Fjg/ojYCswG7ouII+sdnJkrM3N+Zs4fGBhovVNJ0piaHqFn5gPA4Xu2a6E+PzOf7GBfmoRWPHYB31hyev3iyX/b1V6kfrQvty3eCNwDzIuI7RFx3sS3pcloy0uz4ZB59YuHzGtckwTswwg9M88Zpz7UsW40qS08+F7Y/hrMfv/exe3/UjzXq0kCXMtFJfKhgZth82fqFzd/pnFNEmCgS1JlGOiSVBEGuiRVhIEuSRXh8rkqjYsevZh7zl1Yv3jqP3a3GakPGegqjR0vD8BBc+oXG+2X9DqnXFQai6evhW1fqV/c9pXGNUmAga4SWXrYbfDwNfWLD1/TuCYJMNAlqTIMdEmqCANdkirCQJekivC2RZXG+dsu5Yd/0OAXYb17TXebkfqQga7SePrV6TBlZv1io/2SXueUi0rj7Bl3wpZV9YtbVjWuSQIMdJWIgS61x0CXpIow0CWpIvbll0RfGxE7I2LjiH2fjojNEfGjiLg5Ig6d2DYlSePZlxH6KmDRqH13ACdk5luBnwCXdrgvSVKTxg30zFwL/HzUvtsz85Xa5veA2RPQmyaZZY9cDqffVr94+m2Na5KAztyH/sdAw3VNI2IYGAYYHBzswOlURkOX3Fp3/9Yrz9zn13gxpzD0sW++vr36TU8BsOSSW5t6nU5q9L6gufcmdUNbF0Uj4qPAK8ANjY7JzJWZOT8z5w8MDLRzOlXc0sNuZelhDQL0J39dPCQ11HKgR8QyYDFwbmZmxzrSpLV4+rdYPP1b9Ys//WrxkNRQS1MuEbEIWA78ema+0NmWJEmt2JfbFm8E7gHmRcT2iDgPuBo4GLgjIjZExN9McJ+SpHGMO0LPzHPq7P7yBPQiSWqDnxSVpIpw+VyVxpItVzYunnF31/qQ+pUjdEmqCANdpfGhmTfxoZk31S9uuqp4SGrIQFdpLDzk+yw85Pv1i4/dUjwkNWSgS1JFGOiSVBEGuiRVhLctqjRefO2AxsX9DuxeI1KfMtBVGsu2/nnj4nu/3r1GpD7llIskVYSBrtK48PAbufDwG+sXH/hk8ZDUkIGu0lgw7X4WTLu/fvFndxUPSQ0Z6JJUEQa6JFWEgS5JFeFtiyqNp189pHHxgMO614jUpwx0lcb521Y0Lr7na91rROpTTrlIUkXsyy+JvjYidkbExhH7/ktE3BERD9eeZ0xsm5oMlh+5iuVHrqpf3HBp8ZDU0L6M0FcBi0btuwS4KzOPA+6qbUttOWnqZk6aurl+8cl7ioekhsYN9MxcC/x81O6zgOtqX18H/E6H+5IkNanVOfQjMnNH7esngCMaHRgRwxGxLiLW7dq1q8XTSZLG0/ZF0cxMIMeor8zM+Zk5f2BgoN3TSZIaaPW2xZ9FxFGZuSMijgJ2drIpTU47Xp7ZuDh1dvcakfpUq4H+z8AfAlfWnv9vxzrSpHXRo3/WuPiu67vXiNSn9uW2xRuBe4B5EbE9Is6jCPLfiIiHgTNq25KkHhp3hJ6Z5zQoLexwL5rkLjtqJQCf2DG8d3H9R4rnd3y+ix1J/cWP/qs0jj9wS+Pi0xu614jUp/zovyRVhIEuSRVhoEtSRTiHrtLY8tKsxsWD39K9RqQ+ZaCrNFY8dmHj4jtXdq8RqU855SJJFWGgqzSumPVFrpj1xfrFe4eLh6SGnHJRU4YuuXXCXnvuAY81Lj7/kwk7b7c0+tltvfLMLneiqnKELkkVYaBLUkUY6JJUEc6hqzQe+sXcxsUZJ3avEalPGegqjbqrLO7hKovSuJxykaSKMNBVGp+bcxWfm3NV/eJ3lxYPSQ055aLSOGr/JxsXX9jevUakPuUIXZIqoq1Aj4iLIuLBiNgYETdGxJRONSZJak7LgR4Rs4D/CczPzBOA/YAlnWpMktScdufQ3wgcGBEvA1OBx9tvSZPVfS/8auPizFO714jUp1oO9Mx8LCKuAn4K/AK4PTNvH31cRAwDwwCDg4Otnk6TwKeeWNawNrT63cUXq/dtcbBeLng1kQuYSWNpZ8plBnAWcCxwNHBQROx1X1lmrszM+Zk5f2BgoPVOJUljauei6BnAI5m5KzNfBm4C3tWZtjQZXXPMFVxzzBVN1yQV2plD/ylwSkRMpZhyWQis60hXmpRm7PdcSzVJhZZH6Jl5L7AGuA94oPZa/uJHSeqRtu5yycyPAx/vUC+SpDb4SVFJqgjXclFpfGf321qqSSoY6CqNL+48p6WapIJTLpJUEQa6SmPV0MdZNVT/GvtYNUkFp1xUGlPe8FJLNUkFR+iSVBEGuiRVhFMuk1ijVQF7uVJhp1T5vUmNGOgqjbueO7mlmqSCga7S+NKTv9dSTVLBOXRJqggDXaWxeu4lrJ57SdM1SQUDXZIqwkCXpIow0CWpIgx0SaoIb1tUadzy7HtaqkkqGOgqjeufavwpzrFqkgptTblExKERsSYiNkfEpog4tVONafKZEi8yJV5suiap0O4I/QvAv2bm2RHxJmBqB3rSJLXq2MsBWLLlyqZqkgotB3pETAdOA5YBZOYvgV92pi1JUrPaGaEfC+wC/j4i3gasBz6cmf8x8qCIGAaGAQYHB9s4nbql0UqFvX4tSWNrZw79jcBJwDWZ+XbgP4C9PpudmSszc35mzh8YGGjjdJKksbQT6NuB7Zl5b217DUXAS5J6oOUpl8x8IiIejYh5mfljYCHwUOda02Sz5ukzWqpJKrR7l8uFwA21O1y2AH/UfkuarAx0qT1tBXpmbgDmd6gXTXIz9nsWgKdfnd5UTVLBT4qqNK455n8D9e81H6smqeDiXJJUEQa6JFWEgS5JFWGgS1JFeFFUpXH9U7/dUk1SwUBXadzy7Gkt1SQVnHJRaRy1/y6O2n9X0zVJBUfoKo3PzfkMUP9e87FqneCqkKoCR+iSVBEGuiRVhIEuSRVhoEtSRXhRVKXxpV2/21JNUsFAV2nc9fw7W6pJKjjlotKYe8B25h6wvemapIIjdJXGFbOuBurfaz5WTVLBEbokVUTbgR4R+0XEDyPilk40JElqTSdG6B8GNnXgdSRJbWgr0CNiNnAm8HedaUeS1Kp2L4p+HlgOHNyBXjTJfXHnkpZqkgotB3pELAZ2Zub6iDh9jOOGgWGAwcHBVk+nSeA7u09sqabWNFphcuuVZ3a5E3VKO1MuC4APRMRWYDXwvoi4fvRBmbkyM+dn5vyBgYE2TqeqO37KFo6fsqXpmqRCy4GemZdm5uzMHAKWAN/IzKUd60yTzmVHr+Syo1c2XZNU8D50SaqIjnxSNDPvBu7uxGtJklrjCF2SKsJAl6SKcHEulcannvjDlmqSCga6SuO+F36tpZqkglMuKo2Tpm7ipKn1lwUaqyapYKCrNJYfeR3Lj7yu6ZqkgoEuSRVhoEtSRXhRtEIaLbak/8+fkarMEbokVYQjdJXGJx4fbqkmqWCgqzQeenFuSzVJBadcVBoLpm1gwbQNTdckFRyhqzQuPHw1UP+3E41Vk1RwhC5JFWGgS1JFGOiSVBEGuiRVhBdFVRorHrugpZqkQsuBHhFzgH8AjgASWJmZX+hUY5p8trw0u6WapEI7I/RXgIsz876IOBhYHxF3ZOZDHepNk8zCg+8F4K7n39lUTVKh5UDPzB3AjtrXz0fEJmAWYKCrJR8auBmoH9pj1SQVOjKHHhFDwNuBe+vUhoFhgMHBwZbP0WiVvK1Xntnya06UZnvt1PGa3Prp74gmRtt3uUTENOBrwEcy87nR9cxcmZnzM3P+wMBAu6eTJDXQVqBHxP4UYX5DZt7UmZYkSa1oOdAjIoAvA5sy87Oda0mS1Ip25tAXAB8EHoiIPcvgrcjM29pvS5PRRY9e3FJNUqGdu1y+DUQHe9Ekt+PlxtdYxqpJKvjRf5XG4ulrWTx9bdM1SQU/+q/SWHpYMVt3y7OnNVWTVHCELkkVYaBLUkUY6JJUEQa6JFWEF0VVGudvu7SlmqSCga7SePrV6S3VJBX6PtCbXXmwkyvPNXvuiT6+3509404A1jx9RlO1ftfLP8MTrV/eW6dWqhzr/XbjvTmHrtI4e8adrwd3MzVJBQNdkirCQJekijDQJakiDHRJqoi+v8tF1bHskctbqkkqGOgqjRdzSks1SQWnXFQaSw+7laWH1b+Pd6yapIKBrtJYPP1bLJ7+raZrkgoGuiRVRFuBHhGLIuLHEfHvEXFJp5qSJDWv5UCPiP2A/wP8FnA8cE5EHN+pxiRJzWlnhH4y8O+ZuSUzfwmsBs7qTFuSpGZFZrb2jRFnA4sy83/Utj8IvDMzLxh13DAwXNucB/x4nJeeCTzZUlMTq6x9QXl7K2tfUN7eytoXlLe3svYFnevtmMwcGO+gCb8PPTNXAiv39fiIWJeZ8yewpZaUtS8ob29l7QvK21tZ+4Ly9lbWvqD7vbUz5fIYMGfE9uzaPklSD7QT6D8AjouIYyPiTcAS4J8705YkqVktT7lk5isRcQHwb8B+wLWZ+WAHetrn6ZkuK2tfUN7eytoXlLe3svYF5e2trH1Bl3tr+aKoJKlc/KSoJFWEgS5JFVG6QI+IT0bEjyJiQ0TcHhFH97qnPSLi0xGxudbfzRFxaK97AoiI34+IByPitYgoxe1bZVwWIiKujYidEbGx172MFhFzIuKbEfFQ7b/lh3vdE0BETImI70fE/bW+/rzXPY0UEftFxA8j4pZe9zJSRGyNiAdqObauW+ctXaADn87Mt2bmicAtwGW9bmiEO4ATMvOtwE+AS3vczx4bgd8D1va6ESj1shCrgEW9bqKBV4CLM/N44BTgT0vyM3sJeF9mvg04EVgUEaf0uKeRPgxs6nUTDbw3M0/sl/vQJ0RmPjdi8yCgNFdtM/P2zHyltvk9invvey4zN2XmeJ/A7aZSLguRmWuBn/e6j3oyc0dm3lf7+nmKkJrV264gC7trm/vXHqX4OxkRs4Ezgb/rdS9lUbpAB4iIv4yIR4FzKdcIfaQ/Br7e6yZKahbw6Ijt7ZQgnPpFRAwBbwfu7W0nhdq0xgZgJ3BHZpaiL+DzwHLgtV43UkcCt0fE+tryJ13Rk0CPiDsjYmOdx1kAmfnRzJwD3ABcMPardbe32jEfpfgn8g1l6kv9LyKmAV8DPjLqX6s9k5mv1qZAZwMnR8QJve4pIhYDOzNzfa97aeDdmXkSxbTjn0bEad04aU9+p2hmnrGPh94A3AZ8fALb+U/G6y0ilgGLgYXZxZv4m/iZlYHLQrQgIvanCPMbMvOmXvczWmY+ExHfpLgO0esLywuAD0TEbwNTgEMi4vrMXNrjvgDIzMdqzzsj4maKacgJv8ZVuimXiDhuxOZZwOZe9TJaRCyi+CfeBzLzhV73U2IuC9GkiAjgy8CmzPxsr/vZIyIG9tzNFREHAr9BCf5OZualmTk7M4co/nx9oyxhHhEHRcTBe74GfpMu/Q+wdIEOXFmbSvgRxQ+iFLdv1VwNHAzcUbsd6W963RBARPxuRGwHTgVujYh/62U/tQvHe5aF2AR8tUPLQrQlIm4E7gHmRcT2iDiv1z2NsAD4IPC+2p+tDbXRZ68dBXyz9vfxBxRz6KW6RbCEjgC+HRH3A98Hbs3Mf+3Gif3ovyRVRBlH6JKkFhjoklQRBrokVYSBLkkVYaBLUkUY6JJUEQa6JFXE/wMotzPIlQpwuAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, mu, sig = histogram(pdiffs[~is_nan(pdiffs)])\n",
    "mu, sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.6496946597788, 3.34895531281201e-06)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, p = stats.ttest_1samp(pdiffs[~is_nan(pdiffs)], 0)\n",
    "t, p / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdiffs[~is_nan(pdiffs)]) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logistic regression where the unit of observation is the likelihood judgment of a group of five words. In particular, we will estimate the model, including participant-level effects:\n",
    "\n",
    "REPUBLICAN ~ Sum(log odds that each word was spoken by a Republican) + Sum(valence of words) + Participant's party identity + Sum(valence of words) * Participant's party identity\n",
    "\n",
    "where \"REPUBLICAN\" corresponds to a rating >= 3, or a judgment that the list of words was \"more likely to have been spoken by a Republican\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_data = df.copy()\n",
    "lr_data = lr_data.loc[lr_data.party.isin([ 1,2 ])]\n",
    "\n",
    "n = len(lr_data)\n",
    "# Add dummy columns\n",
    "for i in range(1, n):\n",
    "    ids = np.zeros(n)\n",
    "    ids[i] = 1\n",
    "    lr_data[\"participant{}\".format(i)] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_full = np.ravel(lr_data[range(1,6)])\n",
    "Y = Y_full > 2.5\n",
    "X = np.full((n * 5, 4 + n - 1), np.nan)\n",
    "# Sum(log odds that each word was spoken by a Republican)\n",
    "vf = np.vectorize(lambda l: sum(map(lambda w: signals[w], \n",
    "                                    l.split(\", \"))))\n",
    "X[:,0] = vf(np.ravel(lr_data[list_cols]))\n",
    "# Sum(valence of words)\n",
    "vf = np.vectorize(lambda l: sum(map(lambda w: valences[w] - 5, \n",
    "                                    l.split(\", \"))))\n",
    "X[:,1] = vf(np.ravel(lr_data[list_cols]))\n",
    "# Participant's political identity\n",
    "vf = np.vectorize(lambda pid: int(pid == 1))\n",
    "pids = np.repeat(vf(lr_data.party), 5)\n",
    "pids[pids == 0] = -1\n",
    "X[:,2] = pids\n",
    "# Valence of word * Participant's party identity\n",
    "X[:,3] = X[:,1] * X[:,2]\n",
    "for i in range(4, 4 + n - 1):\n",
    "    X[:,i] = np.repeat(lr_data[\"participant{}\".format(i-3)], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y[~np.isnan(Y_full)]\n",
    "X = X[~np.isnan(Y_full)]\n",
    "Y_full = Y_full[~np.isnan(Y_full)]\n",
    "X = X[~np.isnan(Y)]\n",
    "Y_full = Y_full[~np.isnan(Y)]\n",
    "Y = Y[~np.isnan(Y)]\n",
    "Y = Y[~np.isnan(X).any(axis = 1)]\n",
    "Y_full = Y_full[~np.isnan(X).any(axis = 1)]\n",
    "X = X[~np.isnan(X).any(axis = 1),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataframe where the signal indicator is binarized\n",
    "X_binary = X.copy()\n",
    "X_binary[:,0] = [ x > 0 for x in X_binary[:,0] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sabinasloman/.pyenv/versions/2.7.17/envs/lop_env/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2052: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.17635601, -0.06193283, -0.10149069,  0.05907212]),\n",
       " 0.8141810101814082)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = SparseLR(Y, X); logit.coef[:4], logit.auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.7713158 , -0.0720449 , -0.09889211,  0.05852694]),\n",
       " 0.8157231452923424)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = SparseLR(Y, X_binary); logit.coef[:4], logit.auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic GAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticGAM(callbacks=[Deviance(), Diffs(), Accuracy()], \n",
       "   fit_intercept=True, max_iter=100, \n",
       "   terms=s(0) + s(1) + f(2) + s(3) + f(4) + f(5) + f(6) + f(7) + f(8) + f(9) + f(10) + f(11) + f(12) + f(13) + f(14) + f(15) + f(16) + f(17) + f(18) + f(19) + f(20) + f(21) + f(22) + f(23) + f(24) + f(25) + f(26) + f(27) + f(28) + f(29) + f(30) + f(31) + f(32) + f(33) + f(34) + f(35) + f(36) + f(37) + f(38) + f(39) + f(40) + f(41) + f(42) + f(43) + f(44) + f(45) + f(46) + f(47) + f(48) + f(49) + f(50) + f(51) + f(52) + f(53) + f(54) + f(55) + f(56) + f(57) + f(58) + f(59) + f(60) + f(61) + f(62) + f(63) + f(64) + f(65) + f(66) + f(67) + f(68) + f(69) + f(70) + f(71) + f(72) + f(73) + f(74) + f(75) + f(76) + f(77) + f(78) + f(79) + f(80) + f(81) + f(82) + f(83) + f(84) + f(85) + f(86) + f(87) + f(88) + f(89) + f(90) + f(91) + f(92) + f(93) + f(94) + f(95) + f(96) + f(97) + f(98) + f(99) + f(100) + f(101) + f(102) + f(103) + f(104) + f(105) + f(106) + f(107) + f(108) + f(109) + f(110) + f(111) + f(112) + f(113) + f(114) + f(115) + f(116) + f(117) + intercept,\n",
       "   tol=0.0001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_gam = pygam.LogisticGAM(pygam.terms.TermList(*[pygam.s(0), pygam.s(1), \n",
    "                                 pygam.f(2), pygam.s(3)] + \n",
    "                                 [pygam.f(i) for i in range(4, X.shape[1])]))\n",
    "logistic_gam.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_prf(logistic_gam, 0, logit.coef[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as the LR, but a linear model of the full ratings scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 30 Apr 2020</td> <th>  Prob (F-statistic):</th>  <td> 0.194</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:57:09</td>     <th>  Log-Likelihood:    </th> <td> -958.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   575</td>      <th>  AIC:               </th> <td>   2153.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   457</td>      <th>  BIC:               </th> <td>   2667.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   117</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    4.0101</td> <td>    0.335</td> <td>   11.971</td> <td> 0.000</td> <td>    3.352</td> <td>    4.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.1444</td> <td>    0.029</td> <td>    4.906</td> <td> 0.000</td> <td>    0.087</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0501</td> <td>    0.019</td> <td>   -2.572</td> <td> 0.010</td> <td>   -0.088</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.1228</td> <td>    0.335</td> <td>   -0.367</td> <td> 0.714</td> <td>   -0.780</td> <td>    0.535</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0303</td> <td>    0.019</td> <td>    1.599</td> <td> 0.111</td> <td>   -0.007</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.1446</td> <td>    0.909</td> <td>   -0.159</td> <td> 0.874</td> <td>   -1.932</td> <td>    1.642</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0284</td> <td>    0.909</td> <td>    0.031</td> <td> 0.975</td> <td>   -1.758</td> <td>    1.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    1.3104</td> <td>    0.634</td> <td>    2.066</td> <td> 0.039</td> <td>    0.064</td> <td>    2.557</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0333</td> <td>    0.909</td> <td>   -0.037</td> <td> 0.971</td> <td>   -1.820</td> <td>    1.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2786</td> <td>    0.909</td> <td>    0.306</td> <td> 0.759</td> <td>   -1.508</td> <td>    2.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.4145</td> <td>    0.909</td> <td>   -0.456</td> <td> 0.649</td> <td>   -2.201</td> <td>    1.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.0563</td> <td>    0.634</td> <td>   -0.089</td> <td> 0.929</td> <td>   -1.303</td> <td>    1.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.2071</td> <td>    0.635</td> <td>   -0.326</td> <td> 0.744</td> <td>   -1.455</td> <td>    1.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.3575</td> <td>    0.910</td> <td>    0.393</td> <td> 0.695</td> <td>   -1.430</td> <td>    2.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -0.5682</td> <td>    0.909</td> <td>   -0.625</td> <td> 0.532</td> <td>   -2.355</td> <td>    1.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.5127</td> <td>    0.634</td> <td>    0.808</td> <td> 0.419</td> <td>   -0.734</td> <td>    1.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.1811</td> <td>    0.909</td> <td>   -0.199</td> <td> 0.842</td> <td>   -1.968</td> <td>    1.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   -0.0752</td> <td>    0.635</td> <td>   -0.118</td> <td> 0.906</td> <td>   -1.323</td> <td>    1.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   -0.6158</td> <td>    0.909</td> <td>   -0.678</td> <td> 0.498</td> <td>   -2.402</td> <td>    1.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.5404</td> <td>    0.909</td> <td>    0.595</td> <td> 0.552</td> <td>   -1.246</td> <td>    2.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.0389</td> <td>    0.909</td> <td>    0.043</td> <td> 0.966</td> <td>   -1.747</td> <td>    1.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.1140</td> <td>    0.634</td> <td>    0.180</td> <td> 0.858</td> <td>   -1.133</td> <td>    1.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.0663</td> <td>    0.909</td> <td>    0.073</td> <td> 0.942</td> <td>   -1.720</td> <td>    1.853</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.6534</td> <td>    0.634</td> <td>    1.030</td> <td> 0.303</td> <td>   -0.593</td> <td>    1.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   -1.1222</td> <td>    0.909</td> <td>   -1.234</td> <td> 0.218</td> <td>   -2.909</td> <td>    0.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>   -0.5663</td> <td>    0.634</td> <td>   -0.893</td> <td> 0.372</td> <td>   -1.812</td> <td>    0.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>   -0.0228</td> <td>    0.635</td> <td>   -0.036</td> <td> 0.971</td> <td>   -1.270</td> <td>    1.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>   -0.7595</td> <td>    0.909</td> <td>   -0.836</td> <td> 0.404</td> <td>   -2.546</td> <td>    1.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.9948</td> <td>    0.634</td> <td>    1.569</td> <td> 0.117</td> <td>   -0.251</td> <td>    2.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.4529</td> <td>    0.909</td> <td>    0.498</td> <td> 0.619</td> <td>   -1.334</td> <td>    2.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.6425</td> <td>    0.909</td> <td>    0.707</td> <td> 0.480</td> <td>   -1.145</td> <td>    2.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>    0.3083</td> <td>    0.635</td> <td>    0.486</td> <td> 0.627</td> <td>   -0.939</td> <td>    1.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.1669</td> <td>    0.910</td> <td>   -0.183</td> <td> 0.855</td> <td>   -1.955</td> <td>    1.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>    0.0069</td> <td>    0.634</td> <td>    0.011</td> <td> 0.991</td> <td>   -1.239</td> <td>    1.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.2662</td> <td>    0.909</td> <td>    0.293</td> <td> 0.770</td> <td>   -1.520</td> <td>    2.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    0.1605</td> <td>    0.634</td> <td>    0.253</td> <td> 0.800</td> <td>   -1.085</td> <td>    1.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.2032</td> <td>    0.909</td> <td>   -0.223</td> <td> 0.823</td> <td>   -1.989</td> <td>    1.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.4121</td> <td>    0.909</td> <td>   -0.453</td> <td> 0.651</td> <td>   -2.199</td> <td>    1.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.2106</td> <td>    0.909</td> <td>   -0.232</td> <td> 0.817</td> <td>   -1.997</td> <td>    1.576</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>    0.9585</td> <td>    0.634</td> <td>    1.511</td> <td> 0.132</td> <td>   -0.288</td> <td>    2.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>    0.3362</td> <td>    0.909</td> <td>    0.370</td> <td> 0.712</td> <td>   -1.450</td> <td>    2.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>    0.0084</td> <td>    0.909</td> <td>    0.009</td> <td> 0.993</td> <td>   -1.779</td> <td>    1.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -1.3268</td> <td>    0.909</td> <td>   -1.459</td> <td> 0.145</td> <td>   -3.113</td> <td>    0.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -1.4286</td> <td>    0.634</td> <td>   -2.253</td> <td> 0.025</td> <td>   -2.675</td> <td>   -0.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>    0.0515</td> <td>    0.909</td> <td>    0.057</td> <td> 0.955</td> <td>   -1.735</td> <td>    1.838</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.1039</td> <td>    0.909</td> <td>   -0.114</td> <td> 0.909</td> <td>   -1.891</td> <td>    1.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>    0.6299</td> <td>    0.909</td> <td>    0.693</td> <td> 0.489</td> <td>   -1.157</td> <td>    2.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>   -0.5895</td> <td>    0.909</td> <td>   -0.648</td> <td> 0.517</td> <td>   -2.376</td> <td>    1.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>   -0.1907</td> <td>    0.909</td> <td>   -0.210</td> <td> 0.834</td> <td>   -1.977</td> <td>    1.596</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>   -0.9584</td> <td>    0.909</td> <td>   -1.054</td> <td> 0.292</td> <td>   -2.745</td> <td>    0.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>    0.0466</td> <td>    0.909</td> <td>    0.051</td> <td> 0.959</td> <td>   -1.740</td> <td>    1.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>    0.3125</td> <td>    0.634</td> <td>    0.493</td> <td> 0.623</td> <td>   -0.934</td> <td>    1.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>    1.4708</td> <td>    0.909</td> <td>    1.618</td> <td> 0.106</td> <td>   -0.316</td> <td>    3.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>   -0.6922</td> <td>    0.634</td> <td>   -1.091</td> <td> 0.276</td> <td>   -1.939</td> <td>    0.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>   -0.2047</td> <td>    0.909</td> <td>   -0.225</td> <td> 0.822</td> <td>   -1.991</td> <td>    1.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>   <td>   -0.7625</td> <td>    0.909</td> <td>   -0.839</td> <td> 0.402</td> <td>   -2.549</td> <td>    1.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>   <td>    0.2444</td> <td>    0.635</td> <td>    0.385</td> <td> 0.700</td> <td>   -1.003</td> <td>    1.492</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>   <td>   -1.0297</td> <td>    0.909</td> <td>   -1.133</td> <td> 0.258</td> <td>   -2.816</td> <td>    0.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>   <td>    0.6220</td> <td>    0.909</td> <td>    0.684</td> <td> 0.494</td> <td>   -1.165</td> <td>    2.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th>   <td>   -0.2398</td> <td>    0.635</td> <td>   -0.378</td> <td> 0.706</td> <td>   -1.487</td> <td>    1.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x60</th>   <td>   -0.1475</td> <td>    0.909</td> <td>   -0.162</td> <td> 0.871</td> <td>   -1.935</td> <td>    1.639</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x61</th>   <td>    0.8242</td> <td>    0.909</td> <td>    0.907</td> <td> 0.365</td> <td>   -0.962</td> <td>    2.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th>   <td>    0.1393</td> <td>    0.634</td> <td>    0.220</td> <td> 0.826</td> <td>   -1.107</td> <td>    1.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x63</th>   <td>   -0.4569</td> <td>    0.634</td> <td>   -0.720</td> <td> 0.472</td> <td>   -1.703</td> <td>    0.789</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x64</th>   <td>    0.9952</td> <td>    0.909</td> <td>    1.095</td> <td> 0.274</td> <td>   -0.791</td> <td>    2.782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x65</th>   <td>   -0.0937</td> <td>    0.909</td> <td>   -0.103</td> <td> 0.918</td> <td>   -1.880</td> <td>    1.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x66</th>   <td>   -0.0660</td> <td>    0.634</td> <td>   -0.104</td> <td> 0.917</td> <td>   -1.312</td> <td>    1.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x67</th>   <td>    0.6352</td> <td>    0.909</td> <td>    0.699</td> <td> 0.485</td> <td>   -1.151</td> <td>    2.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x68</th>   <td>    0.9792</td> <td>    0.909</td> <td>    1.077</td> <td> 0.282</td> <td>   -0.807</td> <td>    2.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x69</th>   <td>    0.0468</td> <td>    0.909</td> <td>    0.051</td> <td> 0.959</td> <td>   -1.740</td> <td>    1.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x70</th>   <td>    0.0759</td> <td>    0.909</td> <td>    0.083</td> <td> 0.934</td> <td>   -1.711</td> <td>    1.863</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x71</th>   <td>    0.0007</td> <td>    0.909</td> <td>    0.001</td> <td> 0.999</td> <td>   -1.786</td> <td>    1.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x72</th>   <td>   -0.3262</td> <td>    0.634</td> <td>   -0.514</td> <td> 0.607</td> <td>   -1.573</td> <td>    0.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x73</th>   <td>    0.4751</td> <td>    0.634</td> <td>    0.749</td> <td> 0.454</td> <td>   -0.771</td> <td>    1.721</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x74</th>   <td>   -0.0780</td> <td>    0.634</td> <td>   -0.123</td> <td> 0.902</td> <td>   -1.324</td> <td>    1.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x75</th>   <td>    0.0050</td> <td>    0.909</td> <td>    0.005</td> <td> 0.996</td> <td>   -1.782</td> <td>    1.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x76</th>   <td>   -0.1667</td> <td>    0.910</td> <td>   -0.183</td> <td> 0.855</td> <td>   -1.954</td> <td>    1.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x77</th>   <td>   -1.6770</td> <td>    0.635</td> <td>   -2.643</td> <td> 0.009</td> <td>   -2.924</td> <td>   -0.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x78</th>   <td>    0.3280</td> <td>    0.635</td> <td>    0.516</td> <td> 0.606</td> <td>   -0.920</td> <td>    1.576</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x79</th>   <td>   -0.0804</td> <td>    0.910</td> <td>   -0.088</td> <td> 0.930</td> <td>   -1.868</td> <td>    1.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x80</th>   <td>   -0.6615</td> <td>    0.909</td> <td>   -0.728</td> <td> 0.467</td> <td>   -2.448</td> <td>    1.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81</th>   <td>    0.4313</td> <td>    0.909</td> <td>    0.474</td> <td> 0.635</td> <td>   -1.355</td> <td>    2.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x82</th>   <td>    0.5497</td> <td>    0.909</td> <td>    0.605</td> <td> 0.546</td> <td>   -1.237</td> <td>    2.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x83</th>   <td>    0.8410</td> <td>    0.909</td> <td>    0.925</td> <td> 0.355</td> <td>   -0.945</td> <td>    2.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x84</th>   <td>   -0.2063</td> <td>    0.909</td> <td>   -0.227</td> <td> 0.821</td> <td>   -1.993</td> <td>    1.580</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x85</th>   <td>    0.5401</td> <td>    0.634</td> <td>    0.852</td> <td> 0.395</td> <td>   -0.706</td> <td>    1.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x86</th>   <td>   -0.0344</td> <td>    0.909</td> <td>   -0.038</td> <td> 0.970</td> <td>   -1.822</td> <td>    1.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x87</th>   <td>    0.0174</td> <td>    0.910</td> <td>    0.019</td> <td> 0.985</td> <td>   -1.770</td> <td>    1.805</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x88</th>   <td>   -0.1800</td> <td>    0.909</td> <td>   -0.198</td> <td> 0.843</td> <td>   -1.967</td> <td>    1.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x89</th>   <td>   -0.5596</td> <td>    0.909</td> <td>   -0.616</td> <td> 0.538</td> <td>   -2.346</td> <td>    1.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x90</th>   <td>   -0.7274</td> <td>    0.635</td> <td>   -1.146</td> <td> 0.252</td> <td>   -1.974</td> <td>    0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x91</th>   <td>   -0.2563</td> <td>    0.634</td> <td>   -0.404</td> <td> 0.686</td> <td>   -1.503</td> <td>    0.990</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x92</th>   <td>   -0.0287</td> <td>    0.910</td> <td>   -0.032</td> <td> 0.975</td> <td>   -1.816</td> <td>    1.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x93</th>   <td>    0.1697</td> <td>    0.909</td> <td>    0.187</td> <td> 0.852</td> <td>   -1.617</td> <td>    1.956</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x94</th>   <td>   -0.8568</td> <td>    0.909</td> <td>   -0.942</td> <td> 0.346</td> <td>   -2.643</td> <td>    0.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x95</th>   <td>    0.1205</td> <td>    0.635</td> <td>    0.190</td> <td> 0.850</td> <td>   -1.126</td> <td>    1.367</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x96</th>   <td>    0.1012</td> <td>    0.634</td> <td>    0.160</td> <td> 0.873</td> <td>   -1.145</td> <td>    1.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x97</th>   <td>   -0.9560</td> <td>    0.909</td> <td>   -1.052</td> <td> 0.294</td> <td>   -2.743</td> <td>    0.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x98</th>   <td>   -0.0760</td> <td>    0.909</td> <td>   -0.084</td> <td> 0.933</td> <td>   -1.862</td> <td>    1.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x99</th>   <td>    0.6050</td> <td>    0.909</td> <td>    0.665</td> <td> 0.506</td> <td>   -1.182</td> <td>    2.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x100</th>  <td>   -0.1507</td> <td>    0.909</td> <td>   -0.166</td> <td> 0.868</td> <td>   -1.938</td> <td>    1.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x101</th>  <td>    0.5351</td> <td>    0.909</td> <td>    0.589</td> <td> 0.556</td> <td>   -1.251</td> <td>    2.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x102</th>  <td>    1.9439</td> <td>    0.634</td> <td>    3.066</td> <td> 0.002</td> <td>    0.698</td> <td>    3.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x103</th>  <td>    0.3936</td> <td>    0.909</td> <td>    0.433</td> <td> 0.665</td> <td>   -1.393</td> <td>    2.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x104</th>  <td>   -0.1096</td> <td>    0.909</td> <td>   -0.121</td> <td> 0.904</td> <td>   -1.896</td> <td>    1.677</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x105</th>  <td>   -1.0584</td> <td>    0.634</td> <td>   -1.669</td> <td> 0.096</td> <td>   -2.305</td> <td>    0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x106</th>  <td>    0.5503</td> <td>    0.635</td> <td>    0.867</td> <td> 0.386</td> <td>   -0.697</td> <td>    1.798</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x107</th>  <td>    0.4934</td> <td>    0.909</td> <td>    0.543</td> <td> 0.588</td> <td>   -1.293</td> <td>    2.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x108</th>  <td>   -0.0861</td> <td>    0.909</td> <td>   -0.095</td> <td> 0.925</td> <td>   -1.873</td> <td>    1.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x109</th>  <td>   -0.1418</td> <td>    0.909</td> <td>   -0.156</td> <td> 0.876</td> <td>   -1.929</td> <td>    1.645</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x110</th>  <td>   -0.5447</td> <td>    0.909</td> <td>   -0.599</td> <td> 0.549</td> <td>   -2.331</td> <td>    1.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x111</th>  <td>   -0.0512</td> <td>    0.634</td> <td>   -0.081</td> <td> 0.936</td> <td>   -1.298</td> <td>    1.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x112</th>  <td>   -0.3469</td> <td>    0.909</td> <td>   -0.382</td> <td> 0.703</td> <td>   -2.133</td> <td>    1.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x113</th>  <td>   -0.6579</td> <td>    0.909</td> <td>   -0.724</td> <td> 0.470</td> <td>   -2.444</td> <td>    1.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x114</th>  <td>    0.1543</td> <td>    0.634</td> <td>    0.243</td> <td> 0.808</td> <td>   -1.092</td> <td>    1.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x115</th>  <td>    0.1724</td> <td>    0.909</td> <td>    0.190</td> <td> 0.850</td> <td>   -1.614</td> <td>    1.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x116</th>  <td>   -0.7221</td> <td>    0.909</td> <td>   -0.794</td> <td> 0.427</td> <td>   -2.509</td> <td>    1.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x117</th>  <td>   -1.2295</td> <td>    0.909</td> <td>   -1.353</td> <td> 0.177</td> <td>   -3.016</td> <td>    0.557</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x118</th>  <td>   -0.6055</td> <td>    0.909</td> <td>   -0.666</td> <td> 0.506</td> <td>   -2.392</td> <td>    1.181</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.382</td> <th>  Durbin-Watson:     </th> <td>   2.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>  10.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.241</td> <th>  Prob(JB):          </th> <td> 0.00646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.566</td> <th>  Cond. No.          </th> <td>1.48e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 9.87e-31. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.224\n",
       "Model:                            OLS   Adj. R-squared:                  0.025\n",
       "Method:                 Least Squares   F-statistic:                     1.128\n",
       "Date:                Thu, 30 Apr 2020   Prob (F-statistic):              0.194\n",
       "Time:                        14:57:09   Log-Likelihood:                -958.40\n",
       "No. Observations:                 575   AIC:                             2153.\n",
       "Df Residuals:                     457   BIC:                             2667.\n",
       "Df Model:                         117                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          4.0101      0.335     11.971      0.000       3.352       4.668\n",
       "x1             0.1444      0.029      4.906      0.000       0.087       0.202\n",
       "x2            -0.0501      0.019     -2.572      0.010      -0.088      -0.012\n",
       "x3            -0.1228      0.335     -0.367      0.714      -0.780       0.535\n",
       "x4             0.0303      0.019      1.599      0.111      -0.007       0.068\n",
       "x5            -0.1446      0.909     -0.159      0.874      -1.932       1.642\n",
       "x6             0.0284      0.909      0.031      0.975      -1.758       1.815\n",
       "x7             1.3104      0.634      2.066      0.039       0.064       2.557\n",
       "x8            -0.0333      0.909     -0.037      0.971      -1.820       1.753\n",
       "x9             0.2786      0.909      0.306      0.759      -1.508       2.065\n",
       "x10           -0.4145      0.909     -0.456      0.649      -2.201       1.372\n",
       "x11           -0.0563      0.634     -0.089      0.929      -1.303       1.190\n",
       "x12           -0.2071      0.635     -0.326      0.744      -1.455       1.041\n",
       "x13            0.3575      0.910      0.393      0.695      -1.430       2.145\n",
       "x14           -0.5682      0.909     -0.625      0.532      -2.355       1.218\n",
       "x15            0.5127      0.634      0.808      0.419      -0.734       1.760\n",
       "x16           -0.1811      0.909     -0.199      0.842      -1.968       1.606\n",
       "x17           -0.0752      0.635     -0.118      0.906      -1.323       1.172\n",
       "x18           -0.6158      0.909     -0.678      0.498      -2.402       1.170\n",
       "x19            0.5404      0.909      0.595      0.552      -1.246       2.327\n",
       "x20            0.0389      0.909      0.043      0.966      -1.747       1.825\n",
       "x21            0.1140      0.634      0.180      0.858      -1.133       1.361\n",
       "x22            0.0663      0.909      0.073      0.942      -1.720       1.853\n",
       "x23            0.6534      0.634      1.030      0.303      -0.593       1.900\n",
       "x24           -1.1222      0.909     -1.234      0.218      -2.909       0.665\n",
       "x25           -0.5663      0.634     -0.893      0.372      -1.812       0.680\n",
       "x26           -0.0228      0.635     -0.036      0.971      -1.270       1.225\n",
       "x27           -0.7595      0.909     -0.836      0.404      -2.546       1.027\n",
       "x28            0.9948      0.634      1.569      0.117      -0.251       2.241\n",
       "x29            0.4529      0.909      0.498      0.619      -1.334       2.240\n",
       "x30            0.6425      0.909      0.707      0.480      -1.145       2.430\n",
       "x31            0.3083      0.635      0.486      0.627      -0.939       1.556\n",
       "x32           -0.1669      0.910     -0.183      0.855      -1.955       1.621\n",
       "x33            0.0069      0.634      0.011      0.991      -1.239       1.253\n",
       "x34            0.2662      0.909      0.293      0.770      -1.520       2.053\n",
       "x35            0.1605      0.634      0.253      0.800      -1.085       1.406\n",
       "x36           -0.2032      0.909     -0.223      0.823      -1.989       1.583\n",
       "x37           -0.4121      0.909     -0.453      0.651      -2.199       1.375\n",
       "x38           -0.2106      0.909     -0.232      0.817      -1.997       1.576\n",
       "x39            0.9585      0.634      1.511      0.132      -0.288       2.205\n",
       "x40            0.3362      0.909      0.370      0.712      -1.450       2.123\n",
       "x41            0.0084      0.909      0.009      0.993      -1.779       1.795\n",
       "x42           -1.3268      0.909     -1.459      0.145      -3.113       0.460\n",
       "x43           -1.4286      0.634     -2.253      0.025      -2.675      -0.182\n",
       "x44            0.0515      0.909      0.057      0.955      -1.735       1.838\n",
       "x45           -0.1039      0.909     -0.114      0.909      -1.891       1.683\n",
       "x46            0.6299      0.909      0.693      0.489      -1.157       2.416\n",
       "x47           -0.5895      0.909     -0.648      0.517      -2.376       1.197\n",
       "x48           -0.1907      0.909     -0.210      0.834      -1.977       1.596\n",
       "x49           -0.9584      0.909     -1.054      0.292      -2.745       0.828\n",
       "x50            0.0466      0.909      0.051      0.959      -1.740       1.833\n",
       "x51            0.3125      0.634      0.493      0.623      -0.934       1.559\n",
       "x52            1.4708      0.909      1.618      0.106      -0.316       3.257\n",
       "x53           -0.6922      0.634     -1.091      0.276      -1.939       0.554\n",
       "x54           -0.2047      0.909     -0.225      0.822      -1.991       1.582\n",
       "x55           -0.7625      0.909     -0.839      0.402      -2.549       1.024\n",
       "x56            0.2444      0.635      0.385      0.700      -1.003       1.492\n",
       "x57           -1.0297      0.909     -1.133      0.258      -2.816       0.757\n",
       "x58            0.6220      0.909      0.684      0.494      -1.165       2.409\n",
       "x59           -0.2398      0.635     -0.378      0.706      -1.487       1.007\n",
       "x60           -0.1475      0.909     -0.162      0.871      -1.935       1.639\n",
       "x61            0.8242      0.909      0.907      0.365      -0.962       2.611\n",
       "x62            0.1393      0.634      0.220      0.826      -1.107       1.385\n",
       "x63           -0.4569      0.634     -0.720      0.472      -1.703       0.789\n",
       "x64            0.9952      0.909      1.095      0.274      -0.791       2.782\n",
       "x65           -0.0937      0.909     -0.103      0.918      -1.880       1.693\n",
       "x66           -0.0660      0.634     -0.104      0.917      -1.312       1.180\n",
       "x67            0.6352      0.909      0.699      0.485      -1.151       2.422\n",
       "x68            0.9792      0.909      1.077      0.282      -0.807       2.765\n",
       "x69            0.0468      0.909      0.051      0.959      -1.740       1.833\n",
       "x70            0.0759      0.909      0.083      0.934      -1.711       1.863\n",
       "x71            0.0007      0.909      0.001      0.999      -1.786       1.788\n",
       "x72           -0.3262      0.634     -0.514      0.607      -1.573       0.920\n",
       "x73            0.4751      0.634      0.749      0.454      -0.771       1.721\n",
       "x74           -0.0780      0.634     -0.123      0.902      -1.324       1.168\n",
       "x75            0.0050      0.909      0.005      0.996      -1.782       1.792\n",
       "x76           -0.1667      0.910     -0.183      0.855      -1.954       1.621\n",
       "x77           -1.6770      0.635     -2.643      0.009      -2.924      -0.430\n",
       "x78            0.3280      0.635      0.516      0.606      -0.920       1.576\n",
       "x79           -0.0804      0.910     -0.088      0.930      -1.868       1.707\n",
       "x80           -0.6615      0.909     -0.728      0.467      -2.448       1.125\n",
       "x81            0.4313      0.909      0.474      0.635      -1.355       2.218\n",
       "x82            0.5497      0.909      0.605      0.546      -1.237       2.336\n",
       "x83            0.8410      0.909      0.925      0.355      -0.945       2.627\n",
       "x84           -0.2063      0.909     -0.227      0.821      -1.993       1.580\n",
       "x85            0.5401      0.634      0.852      0.395      -0.706       1.786\n",
       "x86           -0.0344      0.909     -0.038      0.970      -1.822       1.753\n",
       "x87            0.0174      0.910      0.019      0.985      -1.770       1.805\n",
       "x88           -0.1800      0.909     -0.198      0.843      -1.967       1.607\n",
       "x89           -0.5596      0.909     -0.616      0.538      -2.346       1.227\n",
       "x90           -0.7274      0.635     -1.146      0.252      -1.974       0.520\n",
       "x91           -0.2563      0.634     -0.404      0.686      -1.503       0.990\n",
       "x92           -0.0287      0.910     -0.032      0.975      -1.816       1.759\n",
       "x93            0.1697      0.909      0.187      0.852      -1.617       1.956\n",
       "x94           -0.8568      0.909     -0.942      0.346      -2.643       0.930\n",
       "x95            0.1205      0.635      0.190      0.850      -1.126       1.367\n",
       "x96            0.1012      0.634      0.160      0.873      -1.145       1.348\n",
       "x97           -0.9560      0.909     -1.052      0.294      -2.743       0.830\n",
       "x98           -0.0760      0.909     -0.084      0.933      -1.862       1.710\n",
       "x99            0.6050      0.909      0.665      0.506      -1.182       2.392\n",
       "x100          -0.1507      0.909     -0.166      0.868      -1.938       1.636\n",
       "x101           0.5351      0.909      0.589      0.556      -1.251       2.321\n",
       "x102           1.9439      0.634      3.066      0.002       0.698       3.190\n",
       "x103           0.3936      0.909      0.433      0.665      -1.393       2.180\n",
       "x104          -0.1096      0.909     -0.121      0.904      -1.896       1.677\n",
       "x105          -1.0584      0.634     -1.669      0.096      -2.305       0.188\n",
       "x106           0.5503      0.635      0.867      0.386      -0.697       1.798\n",
       "x107           0.4934      0.909      0.543      0.588      -1.293       2.280\n",
       "x108          -0.0861      0.909     -0.095      0.925      -1.873       1.701\n",
       "x109          -0.1418      0.909     -0.156      0.876      -1.929       1.645\n",
       "x110          -0.5447      0.909     -0.599      0.549      -2.331       1.242\n",
       "x111          -0.0512      0.634     -0.081      0.936      -1.298       1.195\n",
       "x112          -0.3469      0.909     -0.382      0.703      -2.133       1.440\n",
       "x113          -0.6579      0.909     -0.724      0.470      -2.444       1.128\n",
       "x114           0.1543      0.634      0.243      0.808      -1.092       1.400\n",
       "x115           0.1724      0.909      0.190      0.850      -1.614       1.959\n",
       "x116          -0.7221      0.909     -0.794      0.427      -2.509       1.065\n",
       "x117          -1.2295      0.909     -1.353      0.177      -3.016       0.557\n",
       "x118          -0.6055      0.909     -0.666      0.506      -2.392       1.181\n",
       "==============================================================================\n",
       "Omnibus:                       12.382   Durbin-Watson:                   2.385\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               10.083\n",
       "Skew:                          -0.241   Prob(JB):                      0.00646\n",
       "Kurtosis:                       2.566   Cond. No.                     1.48e+17\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 9.87e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = sm.OLS(Y_full, sm.add_constant(X))\n",
    "res = lm.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 30 Apr 2020</td> <th>  Prob (F-statistic):</th>  <td> 0.224</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:57:12</td>     <th>  Log-Likelihood:    </th> <td> -959.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   575</td>      <th>  AIC:               </th> <td>   2155.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   457</td>      <th>  BIC:               </th> <td>   2669.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   117</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    3.7013</td> <td>    0.338</td> <td>   10.939</td> <td> 0.000</td> <td>    3.036</td> <td>    4.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.6140</td> <td>    0.130</td> <td>    4.739</td> <td> 0.000</td> <td>    0.359</td> <td>    0.869</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0576</td> <td>    0.020</td> <td>   -2.879</td> <td> 0.004</td> <td>   -0.097</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.1067</td> <td>    0.335</td> <td>   -0.319</td> <td> 0.750</td> <td>   -0.765</td> <td>    0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0303</td> <td>    0.019</td> <td>    1.595</td> <td> 0.111</td> <td>   -0.007</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0415</td> <td>    0.911</td> <td>   -0.046</td> <td> 0.964</td> <td>   -1.831</td> <td>    1.748</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0663</td> <td>    0.911</td> <td>    0.073</td> <td> 0.942</td> <td>   -1.724</td> <td>    1.856</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    1.3458</td> <td>    0.635</td> <td>    2.119</td> <td> 0.035</td> <td>    0.098</td> <td>    2.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0358</td> <td>    0.911</td> <td>    0.039</td> <td> 0.969</td> <td>   -1.754</td> <td>    1.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.3191</td> <td>    0.911</td> <td>    0.350</td> <td> 0.726</td> <td>   -1.471</td> <td>    2.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.3402</td> <td>    0.911</td> <td>   -0.373</td> <td> 0.709</td> <td>   -2.130</td> <td>    1.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.0466</td> <td>    0.635</td> <td>   -0.073</td> <td> 0.942</td> <td>   -1.295</td> <td>    1.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.2233</td> <td>    0.636</td> <td>   -0.351</td> <td> 0.726</td> <td>   -1.473</td> <td>    1.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.3754</td> <td>    0.911</td> <td>    0.412</td> <td> 0.681</td> <td>   -1.416</td> <td>    2.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -0.5258</td> <td>    0.911</td> <td>   -0.577</td> <td> 0.564</td> <td>   -2.316</td> <td>    1.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.4609</td> <td>    0.635</td> <td>    0.726</td> <td> 0.469</td> <td>   -0.787</td> <td>    1.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.1694</td> <td>    0.911</td> <td>   -0.186</td> <td> 0.853</td> <td>   -1.960</td> <td>    1.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   -0.1171</td> <td>    0.636</td> <td>   -0.184</td> <td> 0.854</td> <td>   -1.366</td> <td>    1.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   -0.5871</td> <td>    0.910</td> <td>   -0.645</td> <td> 0.519</td> <td>   -2.376</td> <td>    1.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.5864</td> <td>    0.910</td> <td>    0.644</td> <td> 0.520</td> <td>   -1.203</td> <td>    2.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.0454</td> <td>    0.911</td> <td>    0.050</td> <td> 0.960</td> <td>   -1.744</td> <td>    1.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.0619</td> <td>    0.635</td> <td>    0.097</td> <td> 0.922</td> <td>   -1.186</td> <td>    1.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.0912</td> <td>    0.911</td> <td>    0.100</td> <td> 0.920</td> <td>   -1.699</td> <td>    1.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.6666</td> <td>    0.635</td> <td>    1.049</td> <td> 0.295</td> <td>   -0.582</td> <td>    1.915</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   -1.0646</td> <td>    0.911</td> <td>   -1.169</td> <td> 0.243</td> <td>   -2.854</td> <td>    0.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>   -0.5376</td> <td>    0.635</td> <td>   -0.846</td> <td> 0.398</td> <td>   -1.786</td> <td>    0.711</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>   -0.0287</td> <td>    0.636</td> <td>   -0.045</td> <td> 0.964</td> <td>   -1.278</td> <td>    1.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>   -0.6820</td> <td>    0.911</td> <td>   -0.749</td> <td> 0.454</td> <td>   -2.472</td> <td>    1.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    1.0586</td> <td>    0.635</td> <td>    1.666</td> <td> 0.096</td> <td>   -0.190</td> <td>    2.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.4826</td> <td>    0.911</td> <td>    0.530</td> <td> 0.597</td> <td>   -1.307</td> <td>    2.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.7192</td> <td>    0.911</td> <td>    0.790</td> <td> 0.430</td> <td>   -1.070</td> <td>    2.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>    0.2486</td> <td>    0.636</td> <td>    0.391</td> <td> 0.696</td> <td>   -1.000</td> <td>    1.497</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -0.1360</td> <td>    0.911</td> <td>   -0.149</td> <td> 0.881</td> <td>   -1.926</td> <td>    1.655</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.0435</td> <td>    0.635</td> <td>   -0.069</td> <td> 0.945</td> <td>   -1.292</td> <td>    1.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.2636</td> <td>    0.911</td> <td>    0.290</td> <td> 0.772</td> <td>   -1.526</td> <td>    2.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    0.1429</td> <td>    0.635</td> <td>    0.225</td> <td> 0.822</td> <td>   -1.105</td> <td>    1.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.1792</td> <td>    0.910</td> <td>   -0.197</td> <td> 0.844</td> <td>   -1.968</td> <td>    1.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.3779</td> <td>    0.911</td> <td>   -0.415</td> <td> 0.678</td> <td>   -2.168</td> <td>    1.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.2269</td> <td>    0.911</td> <td>   -0.249</td> <td> 0.803</td> <td>   -2.016</td> <td>    1.562</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>    0.9641</td> <td>    0.635</td> <td>    1.517</td> <td> 0.130</td> <td>   -0.285</td> <td>    2.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>    0.3808</td> <td>    0.910</td> <td>    0.418</td> <td> 0.676</td> <td>   -1.408</td> <td>    2.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>    0.0388</td> <td>    0.911</td> <td>    0.043</td> <td> 0.966</td> <td>   -1.751</td> <td>    1.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -1.2791</td> <td>    0.911</td> <td>   -1.404</td> <td> 0.161</td> <td>   -3.069</td> <td>    0.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -1.4435</td> <td>    0.635</td> <td>   -2.272</td> <td> 0.024</td> <td>   -2.692</td> <td>   -0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>    0.0926</td> <td>    0.911</td> <td>    0.102</td> <td> 0.919</td> <td>   -1.697</td> <td>    1.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.0751</td> <td>    0.911</td> <td>   -0.082</td> <td> 0.934</td> <td>   -1.865</td> <td>    1.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>    0.6705</td> <td>    0.911</td> <td>    0.736</td> <td> 0.462</td> <td>   -1.119</td> <td>    2.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>   -0.5624</td> <td>    0.911</td> <td>   -0.617</td> <td> 0.537</td> <td>   -2.353</td> <td>    1.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>   -0.1398</td> <td>    0.911</td> <td>   -0.153</td> <td> 0.878</td> <td>   -1.929</td> <td>    1.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>   -0.8869</td> <td>    0.911</td> <td>   -0.974</td> <td> 0.331</td> <td>   -2.677</td> <td>    0.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>    0.0914</td> <td>    0.911</td> <td>    0.100</td> <td> 0.920</td> <td>   -1.698</td> <td>    1.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>    0.3284</td> <td>    0.635</td> <td>    0.517</td> <td> 0.606</td> <td>   -0.920</td> <td>    1.577</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>    1.5046</td> <td>    0.911</td> <td>    1.652</td> <td> 0.099</td> <td>   -0.285</td> <td>    3.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>   -0.6556</td> <td>    0.635</td> <td>   -1.032</td> <td> 0.303</td> <td>   -1.904</td> <td>    0.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>   -0.1557</td> <td>    0.911</td> <td>   -0.171</td> <td> 0.864</td> <td>   -1.946</td> <td>    1.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>   <td>   -0.7856</td> <td>    0.910</td> <td>   -0.863</td> <td> 0.389</td> <td>   -2.575</td> <td>    1.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>   <td>    0.2383</td> <td>    0.636</td> <td>    0.375</td> <td> 0.708</td> <td>   -1.011</td> <td>    1.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>   <td>   -1.0297</td> <td>    0.911</td> <td>   -1.131</td> <td> 0.259</td> <td>   -2.819</td> <td>    0.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>   <td>    0.6436</td> <td>    0.911</td> <td>    0.707</td> <td> 0.480</td> <td>   -1.147</td> <td>    2.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th>   <td>   -0.2337</td> <td>    0.636</td> <td>   -0.368</td> <td> 0.713</td> <td>   -1.483</td> <td>    1.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x60</th>   <td>   -0.1463</td> <td>    0.911</td> <td>   -0.161</td> <td> 0.872</td> <td>   -1.936</td> <td>    1.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x61</th>   <td>    0.9054</td> <td>    0.911</td> <td>    0.994</td> <td> 0.321</td> <td>   -0.885</td> <td>    2.695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th>   <td>    0.1502</td> <td>    0.635</td> <td>    0.236</td> <td> 0.813</td> <td>   -1.098</td> <td>    1.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x63</th>   <td>   -0.4667</td> <td>    0.635</td> <td>   -0.735</td> <td> 0.463</td> <td>   -1.715</td> <td>    0.782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x64</th>   <td>    1.0717</td> <td>    0.911</td> <td>    1.177</td> <td> 0.240</td> <td>   -0.718</td> <td>    2.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x65</th>   <td>   -0.0334</td> <td>    0.911</td> <td>   -0.037</td> <td> 0.971</td> <td>   -1.823</td> <td>    1.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x66</th>   <td>   -0.0546</td> <td>    0.635</td> <td>   -0.086</td> <td> 0.931</td> <td>   -1.303</td> <td>    1.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x67</th>   <td>    0.7081</td> <td>    0.911</td> <td>    0.777</td> <td> 0.437</td> <td>   -1.082</td> <td>    2.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x68</th>   <td>    1.0109</td> <td>    0.910</td> <td>    1.110</td> <td> 0.267</td> <td>   -0.778</td> <td>    2.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x69</th>   <td>    0.0862</td> <td>    0.911</td> <td>    0.095</td> <td> 0.925</td> <td>   -1.704</td> <td>    1.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x70</th>   <td>    0.0997</td> <td>    0.911</td> <td>    0.109</td> <td> 0.913</td> <td>   -1.690</td> <td>    1.890</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x71</th>   <td>    0.0333</td> <td>    0.911</td> <td>    0.037</td> <td> 0.971</td> <td>   -1.757</td> <td>    1.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x72</th>   <td>   -0.3284</td> <td>    0.635</td> <td>   -0.517</td> <td> 0.605</td> <td>   -1.577</td> <td>    0.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x73</th>   <td>    0.4701</td> <td>    0.635</td> <td>    0.740</td> <td> 0.460</td> <td>   -0.778</td> <td>    1.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x74</th>   <td>   -0.0549</td> <td>    0.635</td> <td>   -0.086</td> <td> 0.931</td> <td>   -1.303</td> <td>    1.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x75</th>   <td>    0.0278</td> <td>    0.911</td> <td>    0.031</td> <td> 0.976</td> <td>   -1.762</td> <td>    1.818</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x76</th>   <td>   -0.1331</td> <td>    0.911</td> <td>   -0.146</td> <td> 0.884</td> <td>   -1.924</td> <td>    1.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x77</th>   <td>   -1.7382</td> <td>    0.635</td> <td>   -2.736</td> <td> 0.006</td> <td>   -2.987</td> <td>   -0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x78</th>   <td>    0.3770</td> <td>    0.636</td> <td>    0.593</td> <td> 0.554</td> <td>   -0.873</td> <td>    1.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x79</th>   <td>   -0.0130</td> <td>    0.911</td> <td>   -0.014</td> <td> 0.989</td> <td>   -1.804</td> <td>    1.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x80</th>   <td>   -0.6549</td> <td>    0.911</td> <td>   -0.719</td> <td> 0.472</td> <td>   -2.444</td> <td>    1.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81</th>   <td>    0.4803</td> <td>    0.911</td> <td>    0.527</td> <td> 0.598</td> <td>   -1.310</td> <td>    2.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x82</th>   <td>    0.6333</td> <td>    0.911</td> <td>    0.695</td> <td> 0.487</td> <td>   -1.157</td> <td>    2.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x83</th>   <td>    0.8997</td> <td>    0.911</td> <td>    0.988</td> <td> 0.324</td> <td>   -0.890</td> <td>    2.690</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x84</th>   <td>   -0.1878</td> <td>    0.910</td> <td>   -0.206</td> <td> 0.837</td> <td>   -1.977</td> <td>    1.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x85</th>   <td>    0.5481</td> <td>    0.635</td> <td>    0.863</td> <td> 0.389</td> <td>   -0.700</td> <td>    1.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x86</th>   <td>   -0.0325</td> <td>    0.911</td> <td>   -0.036</td> <td> 0.972</td> <td>   -1.823</td> <td>    1.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x87</th>   <td>   -0.0010</td> <td>    0.911</td> <td>   -0.001</td> <td> 0.999</td> <td>   -1.792</td> <td>    1.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x88</th>   <td>   -0.1787</td> <td>    0.911</td> <td>   -0.196</td> <td> 0.845</td> <td>   -1.969</td> <td>    1.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x89</th>   <td>   -0.4719</td> <td>    0.911</td> <td>   -0.518</td> <td> 0.605</td> <td>   -2.262</td> <td>    1.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x90</th>   <td>   -0.7513</td> <td>    0.636</td> <td>   -1.182</td> <td> 0.238</td> <td>   -2.000</td> <td>    0.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x91</th>   <td>   -0.2420</td> <td>    0.635</td> <td>   -0.381</td> <td> 0.703</td> <td>   -1.490</td> <td>    1.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x92</th>   <td>   -0.0007</td> <td>    0.911</td> <td>   -0.001</td> <td> 0.999</td> <td>   -1.791</td> <td>    1.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x93</th>   <td>    0.2190</td> <td>    0.910</td> <td>    0.240</td> <td> 0.810</td> <td>   -1.570</td> <td>    2.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x94</th>   <td>   -0.7736</td> <td>    0.911</td> <td>   -0.850</td> <td> 0.396</td> <td>   -2.563</td> <td>    1.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x95</th>   <td>    0.1636</td> <td>    0.635</td> <td>    0.258</td> <td> 0.797</td> <td>   -1.085</td> <td>    1.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x96</th>   <td>    0.0629</td> <td>    0.635</td> <td>    0.099</td> <td> 0.921</td> <td>   -1.185</td> <td>    1.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x97</th>   <td>   -0.9069</td> <td>    0.911</td> <td>   -0.996</td> <td> 0.320</td> <td>   -2.697</td> <td>    0.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x98</th>   <td>   -0.0187</td> <td>    0.910</td> <td>   -0.021</td> <td> 0.984</td> <td>   -1.808</td> <td>    1.771</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x99</th>   <td>    0.6558</td> <td>    0.911</td> <td>    0.720</td> <td> 0.472</td> <td>   -1.134</td> <td>    2.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x100</th>  <td>   -0.1425</td> <td>    0.911</td> <td>   -0.156</td> <td> 0.876</td> <td>   -1.932</td> <td>    1.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x101</th>  <td>    0.5879</td> <td>    0.910</td> <td>    0.646</td> <td> 0.519</td> <td>   -1.201</td> <td>    2.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x102</th>  <td>    1.9443</td> <td>    0.635</td> <td>    3.061</td> <td> 0.002</td> <td>    0.696</td> <td>    3.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x103</th>  <td>    0.4445</td> <td>    0.911</td> <td>    0.488</td> <td> 0.626</td> <td>   -1.346</td> <td>    2.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x104</th>  <td>   -0.0294</td> <td>    0.911</td> <td>   -0.032</td> <td> 0.974</td> <td>   -1.819</td> <td>    1.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x105</th>  <td>   -1.0680</td> <td>    0.635</td> <td>   -1.681</td> <td> 0.093</td> <td>   -2.317</td> <td>    0.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x106</th>  <td>    0.5199</td> <td>    0.636</td> <td>    0.818</td> <td> 0.414</td> <td>   -0.730</td> <td>    1.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x107</th>  <td>    0.4899</td> <td>    0.911</td> <td>    0.538</td> <td> 0.591</td> <td>   -1.300</td> <td>    2.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x108</th>  <td>   -0.0775</td> <td>    0.911</td> <td>   -0.085</td> <td> 0.932</td> <td>   -1.867</td> <td>    1.712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x109</th>  <td>   -0.1052</td> <td>    0.911</td> <td>   -0.115</td> <td> 0.908</td> <td>   -1.895</td> <td>    1.685</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x110</th>  <td>   -0.5097</td> <td>    0.911</td> <td>   -0.560</td> <td> 0.576</td> <td>   -2.300</td> <td>    1.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x111</th>  <td>   -0.0686</td> <td>    0.635</td> <td>   -0.108</td> <td> 0.914</td> <td>   -1.317</td> <td>    1.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x112</th>  <td>   -0.3519</td> <td>    0.911</td> <td>   -0.386</td> <td> 0.699</td> <td>   -2.141</td> <td>    1.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x113</th>  <td>   -0.6272</td> <td>    0.911</td> <td>   -0.689</td> <td> 0.491</td> <td>   -2.416</td> <td>    1.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x114</th>  <td>    0.1474</td> <td>    0.635</td> <td>    0.232</td> <td> 0.817</td> <td>   -1.101</td> <td>    1.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x115</th>  <td>    0.1854</td> <td>    0.910</td> <td>    0.204</td> <td> 0.839</td> <td>   -1.604</td> <td>    1.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x116</th>  <td>   -0.6945</td> <td>    0.911</td> <td>   -0.762</td> <td> 0.446</td> <td>   -2.484</td> <td>    1.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x117</th>  <td>   -1.2256</td> <td>    0.910</td> <td>   -1.346</td> <td> 0.179</td> <td>   -3.015</td> <td>    0.564</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x118</th>  <td>   -0.5443</td> <td>    0.911</td> <td>   -0.598</td> <td> 0.550</td> <td>   -2.334</td> <td>    1.246</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.829</td> <th>  Durbin-Watson:     </th> <td>   2.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  11.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.236</td> <th>  Prob(JB):          </th> <td> 0.00394</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.511</td> <th>  Cond. No.          </th> <td>1.58e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 8.74e-31. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.222\n",
       "Model:                            OLS   Adj. R-squared:                  0.022\n",
       "Method:                 Least Squares   F-statistic:                     1.112\n",
       "Date:                Thu, 30 Apr 2020   Prob (F-statistic):              0.224\n",
       "Time:                        14:57:12   Log-Likelihood:                -959.36\n",
       "No. Observations:                 575   AIC:                             2155.\n",
       "Df Residuals:                     457   BIC:                             2669.\n",
       "Df Model:                         117                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          3.7013      0.338     10.939      0.000       3.036       4.366\n",
       "x1             0.6140      0.130      4.739      0.000       0.359       0.869\n",
       "x2            -0.0576      0.020     -2.879      0.004      -0.097      -0.018\n",
       "x3            -0.1067      0.335     -0.319      0.750      -0.765       0.552\n",
       "x4             0.0303      0.019      1.595      0.111      -0.007       0.068\n",
       "x5            -0.0415      0.911     -0.046      0.964      -1.831       1.748\n",
       "x6             0.0663      0.911      0.073      0.942      -1.724       1.856\n",
       "x7             1.3458      0.635      2.119      0.035       0.098       2.594\n",
       "x8             0.0358      0.911      0.039      0.969      -1.754       1.826\n",
       "x9             0.3191      0.911      0.350      0.726      -1.471       2.109\n",
       "x10           -0.3402      0.911     -0.373      0.709      -2.130       1.450\n",
       "x11           -0.0466      0.635     -0.073      0.942      -1.295       1.202\n",
       "x12           -0.2233      0.636     -0.351      0.726      -1.473       1.027\n",
       "x13            0.3754      0.911      0.412      0.681      -1.416       2.166\n",
       "x14           -0.5258      0.911     -0.577      0.564      -2.316       1.264\n",
       "x15            0.4609      0.635      0.726      0.469      -0.787       1.709\n",
       "x16           -0.1694      0.911     -0.186      0.853      -1.960       1.621\n",
       "x17           -0.1171      0.636     -0.184      0.854      -1.366       1.132\n",
       "x18           -0.5871      0.910     -0.645      0.519      -2.376       1.202\n",
       "x19            0.5864      0.910      0.644      0.520      -1.203       2.376\n",
       "x20            0.0454      0.911      0.050      0.960      -1.744       1.835\n",
       "x21            0.0619      0.635      0.097      0.922      -1.186       1.310\n",
       "x22            0.0912      0.911      0.100      0.920      -1.699       1.881\n",
       "x23            0.6666      0.635      1.049      0.295      -0.582       1.915\n",
       "x24           -1.0646      0.911     -1.169      0.243      -2.854       0.725\n",
       "x25           -0.5376      0.635     -0.846      0.398      -1.786       0.711\n",
       "x26           -0.0287      0.636     -0.045      0.964      -1.278       1.221\n",
       "x27           -0.6820      0.911     -0.749      0.454      -2.472       1.108\n",
       "x28            1.0586      0.635      1.666      0.096      -0.190       2.307\n",
       "x29            0.4826      0.911      0.530      0.597      -1.307       2.272\n",
       "x30            0.7192      0.911      0.790      0.430      -1.070       2.509\n",
       "x31            0.2486      0.636      0.391      0.696      -1.000       1.497\n",
       "x32           -0.1360      0.911     -0.149      0.881      -1.926       1.655\n",
       "x33           -0.0435      0.635     -0.069      0.945      -1.292       1.205\n",
       "x34            0.2636      0.911      0.290      0.772      -1.526       2.053\n",
       "x35            0.1429      0.635      0.225      0.822      -1.105       1.391\n",
       "x36           -0.1792      0.910     -0.197      0.844      -1.968       1.610\n",
       "x37           -0.3779      0.911     -0.415      0.678      -2.168       1.412\n",
       "x38           -0.2269      0.911     -0.249      0.803      -2.016       1.562\n",
       "x39            0.9641      0.635      1.517      0.130      -0.285       2.213\n",
       "x40            0.3808      0.910      0.418      0.676      -1.408       2.170\n",
       "x41            0.0388      0.911      0.043      0.966      -1.751       1.829\n",
       "x42           -1.2791      0.911     -1.404      0.161      -3.069       0.511\n",
       "x43           -1.4435      0.635     -2.272      0.024      -2.692      -0.195\n",
       "x44            0.0926      0.911      0.102      0.919      -1.697       1.883\n",
       "x45           -0.0751      0.911     -0.082      0.934      -1.865       1.715\n",
       "x46            0.6705      0.911      0.736      0.462      -1.119       2.460\n",
       "x47           -0.5624      0.911     -0.617      0.537      -2.353       1.228\n",
       "x48           -0.1398      0.911     -0.153      0.878      -1.929       1.650\n",
       "x49           -0.8869      0.911     -0.974      0.331      -2.677       0.903\n",
       "x50            0.0914      0.911      0.100      0.920      -1.698       1.881\n",
       "x51            0.3284      0.635      0.517      0.606      -0.920       1.577\n",
       "x52            1.5046      0.911      1.652      0.099      -0.285       3.295\n",
       "x53           -0.6556      0.635     -1.032      0.303      -1.904       0.593\n",
       "x54           -0.1557      0.911     -0.171      0.864      -1.946       1.634\n",
       "x55           -0.7856      0.910     -0.863      0.389      -2.575       1.004\n",
       "x56            0.2383      0.636      0.375      0.708      -1.011       1.488\n",
       "x57           -1.0297      0.911     -1.131      0.259      -2.819       0.760\n",
       "x58            0.6436      0.911      0.707      0.480      -1.147       2.434\n",
       "x59           -0.2337      0.636     -0.368      0.713      -1.483       1.015\n",
       "x60           -0.1463      0.911     -0.161      0.872      -1.936       1.644\n",
       "x61            0.9054      0.911      0.994      0.321      -0.885       2.695\n",
       "x62            0.1502      0.635      0.236      0.813      -1.098       1.398\n",
       "x63           -0.4667      0.635     -0.735      0.463      -1.715       0.782\n",
       "x64            1.0717      0.911      1.177      0.240      -0.718       2.862\n",
       "x65           -0.0334      0.911     -0.037      0.971      -1.823       1.756\n",
       "x66           -0.0546      0.635     -0.086      0.931      -1.303       1.193\n",
       "x67            0.7081      0.911      0.777      0.437      -1.082       2.498\n",
       "x68            1.0109      0.910      1.110      0.267      -0.778       2.800\n",
       "x69            0.0862      0.911      0.095      0.925      -1.704       1.876\n",
       "x70            0.0997      0.911      0.109      0.913      -1.690       1.890\n",
       "x71            0.0333      0.911      0.037      0.971      -1.757       1.823\n",
       "x72           -0.3284      0.635     -0.517      0.605      -1.577       0.920\n",
       "x73            0.4701      0.635      0.740      0.460      -0.778       1.719\n",
       "x74           -0.0549      0.635     -0.086      0.931      -1.303       1.193\n",
       "x75            0.0278      0.911      0.031      0.976      -1.762       1.818\n",
       "x76           -0.1331      0.911     -0.146      0.884      -1.924       1.657\n",
       "x77           -1.7382      0.635     -2.736      0.006      -2.987      -0.490\n",
       "x78            0.3770      0.636      0.593      0.554      -0.873       1.627\n",
       "x79           -0.0130      0.911     -0.014      0.989      -1.804       1.778\n",
       "x80           -0.6549      0.911     -0.719      0.472      -2.444       1.135\n",
       "x81            0.4803      0.911      0.527      0.598      -1.310       2.270\n",
       "x82            0.6333      0.911      0.695      0.487      -1.157       2.424\n",
       "x83            0.8997      0.911      0.988      0.324      -0.890       2.690\n",
       "x84           -0.1878      0.910     -0.206      0.837      -1.977       1.601\n",
       "x85            0.5481      0.635      0.863      0.389      -0.700       1.796\n",
       "x86           -0.0325      0.911     -0.036      0.972      -1.823       1.758\n",
       "x87           -0.0010      0.911     -0.001      0.999      -1.792       1.790\n",
       "x88           -0.1787      0.911     -0.196      0.845      -1.969       1.612\n",
       "x89           -0.4719      0.911     -0.518      0.605      -2.262       1.318\n",
       "x90           -0.7513      0.636     -1.182      0.238      -2.000       0.498\n",
       "x91           -0.2420      0.635     -0.381      0.703      -1.490       1.006\n",
       "x92           -0.0007      0.911     -0.001      0.999      -1.791       1.790\n",
       "x93            0.2190      0.910      0.240      0.810      -1.570       2.008\n",
       "x94           -0.7736      0.911     -0.850      0.396      -2.563       1.016\n",
       "x95            0.1636      0.635      0.258      0.797      -1.085       1.412\n",
       "x96            0.0629      0.635      0.099      0.921      -1.185       1.311\n",
       "x97           -0.9069      0.911     -0.996      0.320      -2.697       0.883\n",
       "x98           -0.0187      0.910     -0.021      0.984      -1.808       1.771\n",
       "x99            0.6558      0.911      0.720      0.472      -1.134       2.446\n",
       "x100          -0.1425      0.911     -0.156      0.876      -1.932       1.648\n",
       "x101           0.5879      0.910      0.646      0.519      -1.201       2.377\n",
       "x102           1.9443      0.635      3.061      0.002       0.696       3.192\n",
       "x103           0.4445      0.911      0.488      0.626      -1.346       2.235\n",
       "x104          -0.0294      0.911     -0.032      0.974      -1.819       1.760\n",
       "x105          -1.0680      0.635     -1.681      0.093      -2.317       0.181\n",
       "x106           0.5199      0.636      0.818      0.414      -0.730       1.769\n",
       "x107           0.4899      0.911      0.538      0.591      -1.300       2.280\n",
       "x108          -0.0775      0.911     -0.085      0.932      -1.867       1.712\n",
       "x109          -0.1052      0.911     -0.115      0.908      -1.895       1.685\n",
       "x110          -0.5097      0.911     -0.560      0.576      -2.300       1.280\n",
       "x111          -0.0686      0.635     -0.108      0.914      -1.317       1.180\n",
       "x112          -0.3519      0.911     -0.386      0.699      -2.141       1.437\n",
       "x113          -0.6272      0.911     -0.689      0.491      -2.416       1.162\n",
       "x114           0.1474      0.635      0.232      0.817      -1.101       1.396\n",
       "x115           0.1854      0.910      0.204      0.839      -1.604       1.975\n",
       "x116          -0.6945      0.911     -0.762      0.446      -2.484       1.095\n",
       "x117          -1.2256      0.910     -1.346      0.179      -3.015       0.564\n",
       "x118          -0.5443      0.911     -0.598      0.550      -2.334       1.246\n",
       "==============================================================================\n",
       "Omnibus:                       14.829   Durbin-Watson:                   2.390\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               11.072\n",
       "Skew:                          -0.236   Prob(JB):                      0.00394\n",
       "Kurtosis:                       2.511   Cond. No.                     1.58e+17\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.74e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = sm.OLS(Y_full, sm.add_constant(X_binary))\n",
    "res_binary = lm.fit()\n",
    "res_binary.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear GAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearGAM(callbacks=[Deviance(), Diffs()], fit_intercept=True, \n",
       "   max_iter=100, scale=None, \n",
       "   terms=s(0) + s(1) + f(2) + s(3) + f(4) + f(5) + f(6) + f(7) + f(8) + f(9) + f(10) + f(11) + f(12) + f(13) + f(14) + f(15) + f(16) + f(17) + f(18) + f(19) + f(20) + f(21) + f(22) + f(23) + f(24) + f(25) + f(26) + f(27) + f(28) + f(29) + f(30) + f(31) + f(32) + f(33) + f(34) + f(35) + f(36) + f(37) + f(38) + f(39) + f(40) + f(41) + f(42) + f(43) + f(44) + f(45) + f(46) + f(47) + f(48) + f(49) + f(50) + f(51) + f(52) + f(53) + f(54) + f(55) + f(56) + f(57) + f(58) + f(59) + f(60) + f(61) + f(62) + f(63) + f(64) + f(65) + f(66) + f(67) + f(68) + f(69) + f(70) + f(71) + f(72) + f(73) + f(74) + f(75) + f(76) + f(77) + f(78) + f(79) + f(80) + f(81) + f(82) + f(83) + f(84) + f(85) + f(86) + f(87) + f(88) + f(89) + f(90) + f(91) + f(92) + f(93) + f(94) + f(95) + f(96) + f(97) + f(98) + f(99) + f(100) + f(101) + f(102) + f(103) + f(104) + f(105) + f(106) + f(107) + f(108) + f(109) + f(110) + f(111) + f(112) + f(113) + f(114) + f(115) + f(116) + f(117) + intercept,\n",
       "   tol=0.0001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_gam = pygam.LinearGAM(pygam.terms.TermList(*[pygam.s(0), \n",
    "                             pygam.s(1), pygam.f(2), pygam.s(3)] + \n",
    "                             [pygam.f(i) for i in range(4, X.shape[1])]))\n",
    "linear_gam.fit(X, Y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_prf(linear_gam, 0, res.params[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appendix: Analysis of hypothesized mediators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$accurate \\sim logodds + log(P) + party\\_id + valence + party\\_id \\times valence \\times sign(word) + party\\_identity + party\\_id \\times party\\_identity + political\\_engagement + party\\_id \\times political\\_engagement + \\ldots{}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_data = df.copy()\n",
    "lr_data = lr_data.loc[lr_data.party.isin([ 1,2 ])]\n",
    "\n",
    "n = len(lr_data)\n",
    "# Add dummy columns\n",
    "for i in range(1, n):\n",
    "    ids = np.zeros(n)\n",
    "    ids[i] = 1\n",
    "    lr_data[\"participant{}\".format(i)] = ids\n",
    "\n",
    "n_vars = 9\n",
    "    \n",
    "Y_full = np.ravel(lr_data[range(1,6)])\n",
    "Y = Y_full > 2.5\n",
    "X = np.full((n * 5, n_vars + n - 1), np.nan)\n",
    "# Sum(log odds that each word was spoken by a Republican)\n",
    "vf = np.vectorize(lambda l: sum(map(lambda w: signals[w], \n",
    "                                    l.split(\", \"))))\n",
    "s = vf(np.ravel(lr_data[list_cols]))\n",
    "X[:,0] = np.abs(s)\n",
    "# Sum(log(P) of each word)\n",
    "calc_mP = lambda word: math.log(sum(freq_df.loc[(word,[\"dmetric\",\"rmetric\"])].values) / \n",
    "                                n_utterances, 2)\n",
    "vf = np.vectorize(lambda l: sum(map(calc_mP, l.split(\", \"))))\n",
    "X[:,1] = vf(np.ravel(lr_data[list_cols]))\n",
    "# Participant's political identity\n",
    "vf = np.vectorize(lambda pid: 1 if pid == 1 else -1)\n",
    "pids = np.repeat(vf(lr_data.party), 5)\n",
    "X[:,2] = pids\n",
    "# Valence of word\n",
    "# Sum(valence of words)\n",
    "vf = np.vectorize(lambda l: sum(map(lambda w: valences[w] - 5, \n",
    "                                    l.split(\", \"))))\n",
    "X[:,3] = vf(np.ravel(lr_data[list_cols]))\n",
    "# Valence of word * Participant's party identity * Word is Republican\n",
    "X[:,4] = pids * X[:,3] * np.sign(s) \n",
    "# Party identity\n",
    "X[:,5] = np.repeat(lr_data.party_identity, 5)\n",
    "# Party affiliation x party identity\n",
    "X[:,6] = pids * X[:,5]\n",
    "# Political engagement\n",
    "X[:,7] = np.repeat(lr_data.political_engagement, 5)\n",
    "# Party affiliation x political engagement\n",
    "X[:,8] = pids * X[:,7]\n",
    "# Participant IDs\n",
    "for i in range(n_vars, n_vars + n - 1):\n",
    "    X[:,i] = np.repeat(lr_data[\"participant{}\".format(i-n_vars+1)], 5)\n",
    "\n",
    "polarity = s > 0\n",
    "Y = (Y & polarity) | (~Y & ~polarity)\n",
    "\n",
    "X = X[~np.isnan(Y)]\n",
    "Y = Y[~np.isnan(Y)]\n",
    "Y = Y[~np.isnan(X).any(axis = 1)]\n",
    "X = X[~np.isnan(X).any(axis = 1),:]\n",
    "X = stats.mstats.zscore(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.        , -0.15730473,  0.        ,  0.0384301 ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ]), 575, 0.6160183289460855)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = SparseLR(Y, X); logit.coef[:8], logit.n, logit.auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
