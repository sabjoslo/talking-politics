{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import ma\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import tabletext\n",
    "from pyspan.config import *\n",
    "INPUT_DIR = paths[\"input_dir\"]\n",
    "METRICS_DIR = paths[\"metrics_dir\"]\n",
    "from pyspan import valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_fn = \"survey_terms.txt\"\n",
    "words = open(words_fn, \"r\").read().split(\"\\n\")\n",
    "words = list(filter(lambda s: s.strip(), words))\n",
    "partisan = words[:-20]\n",
    "antonyms = words[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_ = pd.read_csv(\"LoP_Ratings_2.csv\")\n",
    "df = df_[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Status</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>DistributionChannel</th>\n",
       "      <th>UserLanguage</th>\n",
       "      <th>Q5_1</th>\n",
       "      <th>...</th>\n",
       "      <th>194.1</th>\n",
       "      <th>195.1</th>\n",
       "      <th>196.1</th>\n",
       "      <th>Q621</th>\n",
       "      <th>Condition</th>\n",
       "      <th>FL_30_DO</th>\n",
       "      <th>FL_40_DO</th>\n",
       "      <th>Block2_DO</th>\n",
       "      <th>Words_Dem_First_DO</th>\n",
       "      <th>Words_Repub_First_DO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 440 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [StartDate, EndDate, Status, Progress, Duration (in seconds), Finished, RecordedDate, DistributionChannel, UserLanguage, Q5_1, Q5_2, Q5_3, Q5_4, Q610, Q611, Q1429, Q612, Q612_4_TEXT, Q613, Q614, Q614_6_TEXT, Q615, Q616, Q616_8_TEXT, Q617, Q617_7_TEXT, Q618, Q619, Q620, 1000, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 1020, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 1040, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 1060, 61, 62, 63, 64, 65, 66, 67, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 440 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if anyone replied \"no\" to any of the questions on the consent form\n",
    "pd.concat([ df[df[\"Q5_1\"]!=\"Yes\"], df[df[\"Q5_2\"]!=\"Yes\"], \n",
    "            df[df[\"Q5_3\"]!=\"Yes\"], df[df[\"Q5_4\"]!=\"Yes\"] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding some participants\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "# See if anyone didn't finish the survey\n",
    "unfinished = df.loc[df[\"Finished\"] == \"FALSE\"]\n",
    "print \"Excluding some participants\"*(not unfinished.empty)\n",
    "df = df.loc[df[\"Finished\"] == \"TRUE\"]\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine \"Democrat first\" and \"Republican first\" conditions\n",
    "df1 = df[map(str, range(1, 197))]\n",
    "df2 = df[map(lambda n: str(n+.1), range(1, 197))]\n",
    "df2.rename(columns = dict([ (str(i+.1), str(i)) for i in range(1, 197) ]),\n",
    "           inplace = True)\n",
    "df__ = df1.fillna(df2)\n",
    "# Check if anyone left every question blank\n",
    "any(map(lambda i: df__.loc[i].isnull().values.all(), df__.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = { \"I am almost certain the speaker is a Democrat.\": 0,\n",
    "         \"I am reasonably sure the speaker is a Democrat.\": 1,\n",
    "         \"I am unsure but think that the speaker is a Democrat.\": 2,\n",
    "         \"I am unsure but think that the speaker is a Republican.\": 3,\n",
    "         \"I am reasonably sure the speaker is a Republican.\": 4,\n",
    "         \"I am almost certain the speaker is a Republican.\": 5,\n",
    "         \"-99\": np.nan\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df__ = df__.replace(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "minidf = df__[map(str, range(1, 99))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for differences in the order of options. N.B.: MANOVA assumes the DVs are continuous and normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = minidf[map(str, range(1, 99))]\n",
    "condition = df[\"FL_40_DO\"]\n",
    "%Rpush dat condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 5., ..., 1., 1., 1.],\n",
       "       [4., 4., 1., ..., 4., 3., 2.],\n",
       "       [5., 1., 4., ..., 1., 4., 4.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 4., 4., 0.],\n",
       "       [4., 1., 0., ..., 4., 3., 4.],\n",
       "       [4., 0., 0., ..., 1., 0., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%R dat <- matrix(unlist(dat), ncol = 98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Df  Pillai approx F num Df den Df Pr(>F)\n",
      "condition   1 0.52556   0.9834     98     87 0.5336\n",
      "Residuals 184                                      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%R summary <- summary(manova(dat ~ condition))\n",
    "%Rpull summary\n",
    "print summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for cleaning demographic responses\n",
    "def int_(s):\n",
    "    if s == \"-99\":\n",
    "        return np.nan\n",
    "    return int(s)\n",
    "\n",
    "# TODO: Make sure get_gender works on this data!\n",
    "def get_gender(row):\n",
    "    gender = row[\"Q611\"]\n",
    "    if \"f\" in gender.lower():\n",
    "        return \"F\"\n",
    "    if \"m\" in gender.lower():\n",
    "        return \"M\"\n",
    "    return np.nan\n",
    "\n",
    "def get_party_identity(row):\n",
    "    pi = row[\"Q613\"]\n",
    "    if pi == \"-99\":\n",
    "        return np.nan\n",
    "    return int(pi[0])-4\n",
    "\n",
    "def get_political_leanings(row):\n",
    "    pl = row[\"Q614\"]\n",
    "    if pl in (\"-99\", \"Other (please specify)\"):\n",
    "        return np.nan\n",
    "    return {\n",
    "        \"Very Liberal\": -2,\n",
    "        \"Moderately Liberal\": -1,\n",
    "        \"Moderate\": 0,\n",
    "        \"Moderately Conservative\": 1,\n",
    "        \"Very Conservative\": 2\n",
    "    }[pl]\n",
    "    \n",
    "def get_political_engagement(row):\n",
    "    pe = row[\"Q615\"]\n",
    "    if pe == \"-99\":\n",
    "        return np.nan\n",
    "    return int(pe[0])-4\n",
    "    \n",
    "def get_education(row):\n",
    "    edu = row[\"Q617\"]\n",
    "    if edu == \"-99\":\n",
    "        return np.nan\n",
    "    return {\n",
    "        \"High school\": 0,\n",
    "        \"Some college\": 1,\n",
    "        \"Associate's/professional/vocational degree\": 2,\n",
    "        \"Bachelor's degree\": 3,\n",
    "        \"Master's degree\": 4,\n",
    "        \"Higher-level graduate degree\": 5\n",
    "    }[edu]\n",
    "\n",
    "def get_voted(row):\n",
    "    voted = row[\"Q619\"]\n",
    "    if voted == \"Yes\":\n",
    "        return 1\n",
    "    if voted == \"No\":\n",
    "        return 0\n",
    "    return np.nan\n",
    "\n",
    "def get_political_bubble(row):\n",
    "    bubble = row[\"Q620\"]\n",
    "    if bubble == \"-99\":\n",
    "        return np.nan\n",
    "    bubble = filter(lambda s: s.isdigit(), bubble)\n",
    "    # If the participant entered text as a response, just ignore it\n",
    "    # because I can't think of a systematic way to convert text responses\n",
    "    # to numbers\n",
    "    if len(bubble) == 0:\n",
    "        return np.nan\n",
    "    return int_(filter(lambda s: s.isdigit(), bubble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add demographics\n",
    "minidf[\"age\"] = map(int_, df[\"Q610\"])\n",
    "minidf[\"gender\"] = df.apply(get_gender, axis = 1)\n",
    "minidf[\"party\"] = df[\"Q612\"].replace(\"-99\", np.nan)\n",
    "minidf[\"party_identity\"] = df.apply(get_party_identity, axis = 1)\n",
    "minidf[\"political_leanings\"] = df.apply(get_political_leanings,\n",
    "                                        axis = 1)\n",
    "minidf[\"political_engagement\"] = df.apply(get_political_engagement,\n",
    "                                          axis = 1)\n",
    "minidf[\"C-Span\"] = df.apply(lambda row: \"C-Span\" in row[\"Q616\"],\n",
    "                            axis = 1)\n",
    "minidf[\"education\"] = df.apply(get_education, axis = 1)\n",
    "minidf[\"voted\"] = df.apply(get_voted, axis = 1)\n",
    "minidf[\"political_bubble\"] = df.apply(get_political_bubble,\n",
    "                                      axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.268657 of participants (54) failed the attention check\n",
      "Excluding participants who failed the attention check\n",
      "\n",
      "n = 147\n"
     ]
    }
   ],
   "source": [
    "ATC_FAILED = []\n",
    "for i in df__.index:\n",
    "    atcs = df__.loc[i][map(str, range(99, 197))].values\n",
    "    atcs = enumerate(atcs)\n",
    "    atcs = [ (i_, a) for i_, a in atcs if not np.isnan(a) ]\n",
    "    assert len(atcs) == 2\n",
    "    original = df__.loc[i][map(str, range(1, 99))].values\n",
    "    atc_f = not all([ abs(original[i_]-a) <= 1 for i_, a in atcs ])\n",
    "    ATC_FAILED.append(atc_f)\n",
    "minidf[\"ATC_FAILED\"] = ATC_FAILED\n",
    "print \"%f of participants (%d) failed the attention check\"%(ATC_FAILED.count(True)/float(len(ATC_FAILED)), ATC_FAILED.count(True))\n",
    "minidf = minidf[minidf.ATC_FAILED == False]\n",
    "print \"Excluding participants who failed the attention check\\n\"\n",
    "print \"n = {}\".format(len(minidf))\n",
    "minidf = minidf.drop(\"ATC_FAILED\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How much missing data is there?\n",
    "# Each number in this list is the number of questions skipped by a\n",
    "# participant, excluding 0s. So if 3 participants each skip 1 question,\n",
    "# the list will be [ 1, 1, 1 ].\n",
    "nskipped = minidf.isnull().sum(axis = 1)\n",
    "filter(lambda i: i != 0, nskipped.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "minidf = minidf.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "minidf[\"index\"] = minidf.index\n",
    "minidf = minidf.set_index(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "minidf.to_csv(\"responses.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformat and save needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkls = pickle.load(open(METRICS_DIR + \"partial_kls-unigrams\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PKL data to file\n",
    "to_save = [np.nan]*(len(partisan)*4)\n",
    "to_save = np.array(to_save).reshape((len(partisan), 4))\n",
    "\n",
    "for i, w in enumerate(partisan):\n",
    "    to_save[i][0] = i + 1\n",
    "    try:\n",
    "        to_save[i][2] = pkls.loc[w][\"dmetric\"]\n",
    "        to_save[i][3] = pkls.loc[w][\"rmetric\"]\n",
    "    except KeyError:\n",
    "        to_save[i][2] = np.nan\n",
    "        to_save[i][3] = np.nan\n",
    "some_words = pd.DataFrame(to_save, columns = [ \"index\", \"word\",\n",
    "                          \"PKL_D\", \"PKL_R\" ])\n",
    "some_words[\"index\"] = map(int, some_words[\"index\"])\n",
    "some_words = some_words.set_index(\"index\")\n",
    "some_words[\"word\"] = partisan\n",
    "some_words[\"google_sentiment\"] = map(lambda w: valence.get_valence(w, use = \"google\")[0], \n",
    "                                     partisan)\n",
    "some_words[\"pattern_sentiment\"] = map(lambda w: valence.get_valence(w, use = \"pattern\")[0], \n",
    "                                      partisan)\n",
    "some_words[\"crr\"] = map(lambda w: valence.get_valence(w, use = \"crr\")[0], partisan)\n",
    "some_words.to_csv(\"partisan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save antonyms data to file\n",
    "to_save = [np.nan]*(len(antonyms)*5)\n",
    "to_save = np.array(to_save).reshape((len(antonyms), 5))\n",
    "\n",
    "positive = [ \"joy\", \"plentiful\", \"qualified\", \"famous\", \"clever\",\n",
    "             \"accurate\", \"superior\", \"laugh\", \"praise\", \"sweet\" ]\n",
    "negative = [ \"inferior\", \"cry\", \"blame\", \"bitter\", \"sorrow\",\n",
    "             \"scarce\", \"unqualified\", \"unknown\", \"stupid\",\n",
    "             \"inaccurate\" ]\n",
    "for i, w in enumerate(antonyms):\n",
    "    to_save[i][0] = i + 79\n",
    "    to_save[i][2] = pkls.loc[w][\"dmetric\"]\n",
    "    to_save[i][3] = pkls.loc[w][\"rmetric\"]\n",
    "some_words = pd.DataFrame(to_save, columns = [ \"index\", \"word\",\n",
    "                          \"PKL_D\", \"PKL_R\", \"valence\" ])\n",
    "some_words[\"index\"] = map(int, some_words[\"index\"])\n",
    "some_words = some_words.set_index(\"index\")\n",
    "some_words[\"word\"] = antonyms\n",
    "get_valence = lambda w: \"POS\" if w in positive else \"NEG\"\n",
    "some_words[\"valence\"] = map(get_valence, antonyms)\n",
    "some_words[\"google_sentiment\"] = map(lambda w: valence.get_valence(w, use = \"google\")[0], antonyms)\n",
    "some_words[\"pattern_sentiment\"] = map(lambda w: valence.get_valence(w, use = \"pattern\")[0], \n",
    "                                      antonyms)\n",
    "some_words[\"crr\"] = map(lambda w: valence.get_valence(w, use = \"crr\")[0], antonyms)\n",
    "some_words.to_csv(\"antonyms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
